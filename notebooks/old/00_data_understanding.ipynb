{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7badf285",
   "metadata": {},
   "source": [
    "# Data Understanding & Exploration\n",
    "\n",
    "**Project**: Spondylolisthesis MAHT-Net Research\n",
    "\n",
    "**Objective**: Thoroughly understand the dataset structure, annotations, and characteristics before model development.\n",
    "\n",
    "**Dataset**: 716 Lateral Lumbar X-ray Images with Keypoint Annotations\n",
    "- 4 vertebrae per image: L3, L4, L5, S1\n",
    "- 4 corner keypoints per vertebra (16 total per image)\n",
    "- Bounding boxes for each vertebra\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 1.1: Initial Data Exploration\n",
    "\n",
    "This notebook covers:\n",
    "1. **Load and parse JSON annotation files**\n",
    "2. **Understand annotation format** (boxes, keypoints, labels)\n",
    "3. **Count total images and annotations**\n",
    "4. **Analyze data distribution** (train/val/test splits, demographics)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ffcda",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2f7ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme(style=\"darkgrid\", palette=\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5b4b3",
   "metadata": {},
   "source": [
    "## 2. Define Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a066b339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/mnourdine/phd/spondylolisthesis-maht-net\n",
      "\n",
      "Checking data directories...\n",
      "✓ Train images: True - /Users/mnourdine/phd/spondylolisthesis-maht-net/data/Train/Keypointrcnn_data/images/train\n",
      "✓ Train labels: True - /Users/mnourdine/phd/spondylolisthesis-maht-net/data/Train/Keypointrcnn_data/labels/train\n",
      "✓ Val images:   True - /Users/mnourdine/phd/spondylolisthesis-maht-net/data/Train/Keypointrcnn_data/images/val\n",
      "✓ Val labels:   True - /Users/mnourdine/phd/spondylolisthesis-maht-net/data/Train/Keypointrcnn_data/labels/val\n",
      "\n",
      "✓ Output directories created at: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs\n"
     ]
    }
   ],
   "source": [
    "NOTEBOOK_DIR = Path.cwd()  # Current working directory when running notebook\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent  # Go up one level to project root\n",
    "\n",
    "# Data directories - Fixed to match actual structure\n",
    "DATA_DIR = PROJECT_ROOT / 'data'  # Note: data/ due to nested structure\n",
    "TRAIN_DIR = DATA_DIR / 'Train' / 'Keypointrcnn_data'\n",
    "VAL_DIR = TRAIN_DIR  # Val is within the same structure\n",
    "\n",
    "# Image directories\n",
    "TRAIN_IMAGES_DIR = TRAIN_DIR / 'images' / 'train'\n",
    "VAL_IMAGES_DIR = TRAIN_DIR / 'images' / 'val'\n",
    "\n",
    "# Label directories\n",
    "TRAIN_LABELS_DIR = TRAIN_DIR / 'labels' / 'train'\n",
    "VAL_LABELS_DIR = TRAIN_DIR / 'labels' / 'val'\n",
    "\n",
    "# Output directories\n",
    "FIGURES_DIR = PROJECT_ROOT / 'docs' / 'figures'\n",
    "STATS_DIR = PROJECT_ROOT / 'docs' / 'statistics'\n",
    "QUALITY_DIR = PROJECT_ROOT / 'docs' / 'quality'\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STATS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "QUALITY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Verify directories exist\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(\"\\nChecking data directories...\")\n",
    "print(f\"✓ Train images: {TRAIN_IMAGES_DIR.exists()} - {TRAIN_IMAGES_DIR}\")\n",
    "print(f\"✓ Train labels: {TRAIN_LABELS_DIR.exists()} - {TRAIN_LABELS_DIR}\")\n",
    "print(f\"✓ Val images:   {VAL_IMAGES_DIR.exists()} - {VAL_IMAGES_DIR}\")\n",
    "print(f\"✓ Val labels:   {VAL_LABELS_DIR.exists()} - {VAL_LABELS_DIR}\")\n",
    "print(f\"\\n✓ Output directories created at: {PROJECT_ROOT / 'docs'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8eca3",
   "metadata": {},
   "source": [
    "## 3. Load and Parse Sample Annotation\n",
    "\n",
    "Let's start by loading a single annotation file to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3018a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 494 JSON annotation files in training set\n",
      "\n",
      "First 5 files:\n",
      "  - 3209-F-073Y1_jpg.rf.b3686ffe92cdefd4f386611cd2115d2b.json\n",
      "  - 3210-M-067Y1_jpg.rf.0ec3a0fe3dc1fa4bf5eb776537218e1d.json\n",
      "  - 3211-F-034Y1_jpg.rf.f998ff2b707b284dc4cb96eae9df23fa.json\n",
      "  - 3213-M-057Y1_jpg.rf.a40521ebadddc993939db8bd83cae125.json\n",
      "  - 3214-F-069Y1_jpg.rf.3dd82f2d5fddbf67bec119ce60f74162.json\n"
     ]
    }
   ],
   "source": [
    "# Get list of all JSON files in training set\n",
    "train_json_files = sorted(list(TRAIN_LABELS_DIR.glob('*.json')))\n",
    "\n",
    "print(f\"Found {len(train_json_files)} JSON annotation files in training set\")\n",
    "print(f\"\\nFirst 5 files:\")\n",
    "for f in train_json_files[:5]:\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e42d070a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sample annotation: 3209-F-073Y1_jpg.rf.b3686ffe92cdefd4f386611cd2115d2b.json\n",
      "\n",
      "Annotation Structure:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "boxes": [
        [
         331,
         1,
         405,
         37
        ],
        [
         309,
         39,
         392,
         87
        ],
        [
         288,
         87,
         376,
         137
        ],
        [
         275,
         142,
         356,
         189
        ],
        [
         273,
         196,
         354,
         247
        ],
        [
         283,
         244,
         371,
         300
        ],
        [
         308,
         288,
         395,
         346
        ],
        [
         344,
         331,
         446,
         380
        ]
       ],
       "keypoints": [
        [
         [
          331,
          28,
          1
         ],
         [
          396,
          37,
          1
         ],
         [
          357,
          1,
          1
         ],
         [
          405,
          9,
          1
         ]
        ],
        [
         [
          309,
          73,
          1
         ],
         [
          377,
          87,
          1
         ],
         [
          324,
          39,
          1
         ],
         [
          392,
          49,
          1
         ]
        ],
        [
         [
          288,
          124,
          1
         ],
         [
          360,
          137,
          1
         ],
         [
          304,
          87,
          1
         ],
         [
          376,
          93,
          1
         ]
        ],
        [
         [
          275,
          185,
          1
         ],
         [
          349,
          189,
          1
         ],
         [
          283,
          142,
          1
         ],
         [
          356,
          144,
          1
         ]
        ],
        [
         [
          276,
          247,
          1
         ],
         [
          354,
          237,
          1
         ],
         [
          273,
          204,
          1
         ],
         [
          343,
          196,
          1
         ]
        ],
        [
         [
          298,
          300,
          1
         ],
         [
          371,
          281,
          1
         ],
         [
          283,
          263,
          1
         ],
         [
          355,
          244,
          1
         ]
        ],
        [
         [
          327,
          346,
          1
         ],
         [
          395,
          324,
          1
         ],
         [
          308,
          311,
          1
         ],
         [
          377,
          288,
          1
         ]
        ],
        [
         [
          410,
          380,
          1
         ],
         [
          446,
          363,
          1
         ],
         [
          344,
          358,
          1
         ],
         [
          406,
          331,
          1
         ]
        ]
       ],
       "labels": [
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0
       ]
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import JSON, display\n",
    "\n",
    "# Load a sample annotation file\n",
    "sample_json_file = train_json_files[0]\n",
    "print(f\"Loading sample annotation: {sample_json_file.name}\\n\")\n",
    "\n",
    "with open(sample_json_file, 'r') as f:\n",
    "    sample_annotation = json.load(f)\n",
    "\n",
    "# Display the annotation structure\n",
    "print(\"Annotation Structure:\")\n",
    "print(\"=\" * 60)\n",
    "# Interactive, nicely formatted JSON in Jupyter\n",
    "display(JSON(sample_annotation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583965ff",
   "metadata": {},
   "source": [
    "### Understanding the Annotation Format\n",
    "\n",
    "**Structure Breakdown**:\n",
    "```json\n",
    "{\n",
    "  \"boxes\": [[x1, y1, x2, y2], ...],        // 4 bounding boxes (one per vertebra)\n",
    "  \"keypoints\": [[[x,y,v], ...], ...],      // 4 sets of 4 keypoints (16 total)\n",
    "  \"labels\": [0, 0, 0, 0]                   // Class labels (all vertebrae = 0)\n",
    "}\n",
    "```\n",
    "\n",
    "**Details**:\n",
    "- **boxes**: Bounding box format `[x_min, y_min, x_max, y_max]`\n",
    "  - (x_min, y_min) = top-left corner\n",
    "  - (x_max, y_max) = bottom-right corner\n",
    "  \n",
    "- **keypoints**: Each vertebra has 4 corner points `[x, y, visibility]`\n",
    "  - x, y = pixel coordinates\n",
    "  - visibility = 1 (visible) or 0 (occluded)\n",
    "  - Order: Top-Left, Top-Right, Bottom-Left, Bottom-Right\n",
    "  \n",
    "- **labels**: All set to 0 (single class: vertebra)\n",
    "\n",
    "**Vertebra Order**: L3 → L4 → L5 → S1 (top to bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5fec687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Annotation Analysis:\n",
      "============================================================\n",
      "Number of bounding boxes: 8\n",
      "Number of keypoint sets:  8\n",
      "Number of labels:         8\n",
      "\n",
      "Keypoints per vertebra:   4\n",
      "Total keypoints:          32\n",
      "\n",
      "============================================================\n",
      "First Vertebra (L3) Details:\n",
      "============================================================\n",
      "Bounding box: [331, 1, 405, 37]\n",
      "  - Top-left:     (331, 1)\n",
      "  - Bottom-right: (405, 37)\n",
      "  - Width:  74 pixels\n",
      "  - Height: 36 pixels\n",
      "\n",
      "Keypoints (4 corners):\n",
      "  1. Top-Left     - (331,  28) - Visible\n",
      "  2. Top-Right    - (396,  37) - Visible\n",
      "  3. Bottom-Left  - (357,   1) - Visible\n",
      "  4. Bottom-Right - (405,   9) - Visible\n"
     ]
    }
   ],
   "source": [
    "# Analyze the sample annotation\n",
    "print(\"\\nAnnotation Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Number of bounding boxes: {len(sample_annotation['boxes'])}\")\n",
    "print(f\"Number of keypoint sets:  {len(sample_annotation['keypoints'])}\")\n",
    "print(f\"Number of labels:         {len(sample_annotation['labels'])}\")\n",
    "\n",
    "# Check keypoint structure\n",
    "print(f\"\\nKeypoints per vertebra:   {len(sample_annotation['keypoints'][0])}\")\n",
    "print(f\"Total keypoints:          {len(sample_annotation['keypoints']) * len(sample_annotation['keypoints'][0])}\")\n",
    "\n",
    "# Display first vertebra details\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"First Vertebra (L3) Details:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Bounding box: {sample_annotation['boxes'][0]}\")\n",
    "print(f\"  - Top-left:     ({sample_annotation['boxes'][0][0]}, {sample_annotation['boxes'][0][1]})\")\n",
    "print(f\"  - Bottom-right: ({sample_annotation['boxes'][0][2]}, {sample_annotation['boxes'][0][3]})\")\n",
    "print(f\"  - Width:  {sample_annotation['boxes'][0][2] - sample_annotation['boxes'][0][0]} pixels\")\n",
    "print(f\"  - Height: {sample_annotation['boxes'][0][3] - sample_annotation['boxes'][0][1]} pixels\")\n",
    "\n",
    "print(f\"\\nKeypoints (4 corners):\")\n",
    "corner_names = ['Top-Left', 'Top-Right', 'Bottom-Left', 'Bottom-Right']\n",
    "for i, (kp, name) in enumerate(zip(sample_annotation['keypoints'][0], corner_names)):\n",
    "    x, y, vis = kp\n",
    "    vis_str = \"Visible\" if vis == 1 else \"Occluded\"\n",
    "    print(f\"  {i+1}. {name:12} - ({x:3.0f}, {y:3.0f}) - {vis_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad169e6",
   "metadata": {},
   "source": [
    "## 4. Parse All Annotations\n",
    "\n",
    "Now let's load all annotations from both training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49425e86",
   "metadata": {},
   "source": [
    "## 3.5 Convert TXT Annotations to JSON\n",
    "\n",
    "Some annotations are in YOLO `.txt` format. Let's convert them to JSON format first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb0c71b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Converting TXT annotations to JSON format\n",
      "============================================================\n",
      "\n",
      "Train set:\n",
      "Found 155 .txt files to convert\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013128995895385742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Converting TXT to JSON",
       "rate": null,
       "total": 155,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a292a9b1c443f8856620b0a3b51801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting TXT to JSON:   0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Converted: 155\n",
      "✗ Failed:    0\n",
      "\n",
      "Validation set:\n",
      "Found 59 .txt files to convert\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0038559436798095703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Converting TXT to JSON",
       "rate": null,
       "total": 59,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ceae41875e4a379907a34fd722d0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting TXT to JSON:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Converted: 59\n",
      "✗ Failed:    0\n",
      "\n",
      "============================================================\n",
      "Total converted: 214\n",
      "Total failed:    0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def convert_yolo_to_json(txt_path, image_width=512, image_height=512):\n",
    "    \"\"\"\n",
    "    Convert YOLO format TXT file to JSON format.\n",
    "    \n",
    "    YOLO format per line: class x_center y_center width height x1 y1 v1 x2 y2 v2 x3 y3 v3 x4 y4 v4\n",
    "    - Values are normalized (0-1)\n",
    "    - Need to denormalize to pixel coordinates\n",
    "    \n",
    "    Args:\n",
    "        txt_path: Path to .txt annotation file\n",
    "        image_width: Image width in pixels (default 512)\n",
    "        image_height: Image height in pixels (default 512)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with boxes, keypoints, and labels\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    keypoints = []\n",
    "    labels = []\n",
    "    \n",
    "    try:\n",
    "        with open(txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 17:  # class + bbox(4) + keypoints(4*3)\n",
    "                continue\n",
    "            \n",
    "            # Parse class\n",
    "            class_id = int(parts[0])\n",
    "            labels.append(class_id)\n",
    "            \n",
    "            # Parse normalized bbox: x_center, y_center, width, height\n",
    "            x_center_norm = float(parts[1])\n",
    "            y_center_norm = float(parts[2])\n",
    "            width_norm = float(parts[3])\n",
    "            height_norm = float(parts[4])\n",
    "            \n",
    "            # Convert to pixel coordinates and to [x_min, y_min, x_max, y_max]\n",
    "            x_center = x_center_norm * image_width\n",
    "            y_center = y_center_norm * image_height\n",
    "            width = width_norm * image_width\n",
    "            height = height_norm * image_height\n",
    "            \n",
    "            x_min = int(x_center - width / 2)\n",
    "            y_min = int(y_center - height / 2)\n",
    "            x_max = int(x_center + width / 2)\n",
    "            y_max = int(y_center + height / 2)\n",
    "            \n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "            \n",
    "            # Parse keypoints (4 keypoints: x, y, visibility)\n",
    "            kps = []\n",
    "            for i in range(4):\n",
    "                idx = 5 + i * 3\n",
    "                if idx + 2 < len(parts):\n",
    "                    x_norm = float(parts[idx])\n",
    "                    y_norm = float(parts[idx + 1])\n",
    "                    vis = int(parts[idx + 2])\n",
    "                    \n",
    "                    # Convert to pixel coordinates\n",
    "                    x = int(x_norm * image_width)\n",
    "                    y = int(y_norm * image_height)\n",
    "                    \n",
    "                    kps.append([x, y, vis])\n",
    "            \n",
    "            keypoints.append(kps)\n",
    "        \n",
    "        return {\n",
    "            'boxes': boxes,\n",
    "            'keypoints': keypoints,\n",
    "            'labels': labels\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {txt_path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def convert_all_txt_to_json(label_dir, image_dir=None):\n",
    "    \"\"\"\n",
    "    Convert all .txt files in a directory to .json format.\n",
    "    \n",
    "    Args:\n",
    "        label_dir: Directory containing .txt annotation files\n",
    "        image_dir: Directory containing images (to get actual dimensions)\n",
    "    \"\"\"\n",
    "    txt_files = list(Path(label_dir).glob('*.txt'))\n",
    "    \n",
    "    print(f\"Found {len(txt_files)} .txt files to convert\")\n",
    "    \n",
    "    converted = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for txt_file in tqdm(txt_files, desc=\"Converting TXT to JSON\"):\n",
    "        # Get corresponding image to determine dimensions\n",
    "        # Try to find the image file\n",
    "        image_width = 512  # Default\n",
    "        image_height = 512  # Default\n",
    "        \n",
    "        if image_dir:\n",
    "            # Extract base name without extension\n",
    "            base_name = txt_file.stem.replace('.txt', '')\n",
    "            \n",
    "            # Try different image extensions\n",
    "            for ext in ['.jpg', '.png', '.jpeg']:\n",
    "                img_path = Path(image_dir) / f\"{base_name}{ext}\"\n",
    "                if img_path.exists():\n",
    "                    try:\n",
    "                        from PIL import Image\n",
    "                        with Image.open(img_path) as img:\n",
    "                            image_width, image_height = img.size\n",
    "                    except:\n",
    "                        pass\n",
    "                    break\n",
    "        \n",
    "        # Convert to JSON format\n",
    "        json_data = convert_yolo_to_json(txt_file, image_width, image_height)\n",
    "        \n",
    "        if json_data:\n",
    "            # Save as JSON file (same name, different extension)\n",
    "            json_file = txt_file.with_suffix('.json')\n",
    "            with open(json_file, 'w') as f:\n",
    "                json.dump(json_data, f, indent=2)\n",
    "            converted += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "    \n",
    "    print(f\"\\n✓ Converted: {converted}\")\n",
    "    print(f\"✗ Failed:    {failed}\")\n",
    "    \n",
    "    return converted, failed\n",
    "\n",
    "\n",
    "# Convert all TXT files in train and val directories\n",
    "print(\"=\" * 60)\n",
    "print(\"Converting TXT annotations to JSON format\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nTrain set:\")\n",
    "train_converted, train_failed = convert_all_txt_to_json(\n",
    "    TRAIN_LABELS_DIR, \n",
    "    TRAIN_IMAGES_DIR\n",
    ")\n",
    "\n",
    "print(\"\\nValidation set:\")\n",
    "val_converted, val_failed = convert_all_txt_to_json(\n",
    "    VAL_LABELS_DIR,\n",
    "    VAL_IMAGES_DIR\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Total converted: {train_converted + val_converted}\")\n",
    "print(f\"Total failed:    {train_failed + val_failed}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1added",
   "metadata": {},
   "source": [
    "**Note**: The dataset originally contained a mix of JSON and YOLO-format TXT annotations. We successfully converted all 214 TXT files (155 train + 59 val) to JSON format for consistency. All annotations are now in a uniform JSON format with boxes, keypoints, and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f13510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all annotations...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006152153015136719,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading from train",
       "rate": null,
       "total": 494,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc648d07c5ce452a8f6d85a79e5f3972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading from train:   0%|          | 0/494 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0037119388580322266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading from val",
       "rate": null,
       "total": 204,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f89923596674652861b24ddc9d6c72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading from val:   0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loaded 494 training annotations\n",
      "✓ Loaded 204 validation annotations\n",
      "✓ Total: 698 annotations\n"
     ]
    }
   ],
   "source": [
    "def load_annotations(json_dir):\n",
    "    \"\"\"\n",
    "    Load all JSON annotations from a directory.\n",
    "    \n",
    "    Args:\n",
    "        json_dir: Path to directory containing JSON files\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing annotation data\n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    json_files = sorted(list(Path(json_dir).glob('*.json')))\n",
    "    \n",
    "    for json_file in tqdm(json_files, desc=f\"Loading from {json_dir.name}\"):\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                data['filename'] = json_file.name\n",
    "                data['filepath'] = str(json_file)\n",
    "                annotations.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {json_file.name}: {e}\")\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "# Load all annotations\n",
    "print(\"Loading all annotations...\\n\")\n",
    "train_annotations = load_annotations(TRAIN_LABELS_DIR)\n",
    "val_annotations = load_annotations(VAL_LABELS_DIR)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(train_annotations)} training annotations\")\n",
    "print(f\"✓ Loaded {len(val_annotations)} validation annotations\")\n",
    "print(f\"✓ Total: {len(train_annotations) + len(val_annotations)} annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a7515",
   "metadata": {},
   "source": [
    "## 5. Count Images and Verify Pairing\n",
    "\n",
    "Check that every annotation has a corresponding image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ddb28639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "============================================================\n",
      "Training Set:\n",
      "  Images:      494\n",
      "  Annotations: 494\n",
      "  Match: ✓\n",
      "\n",
      "Validation Set:\n",
      "  Images:      204\n",
      "  Annotations: 204\n",
      "  Match: ✓\n",
      "\n",
      "Total Dataset:\n",
      "  Images:      698\n",
      "  Annotations: 698\n",
      "\n",
      "Split Distribution:\n",
      "  Train: 70.8%\n",
      "  Val:   29.2%\n"
     ]
    }
   ],
   "source": [
    "# Count image files\n",
    "train_images = list(TRAIN_IMAGES_DIR.glob('*.jpg')) + list(TRAIN_IMAGES_DIR.glob('*.png'))\n",
    "val_images = list(VAL_IMAGES_DIR.glob('*.jpg')) + list(VAL_IMAGES_DIR.glob('*.png'))\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training Set:\")\n",
    "print(f\"  Images:      {len(train_images)}\")\n",
    "print(f\"  Annotations: {len(train_annotations)}\")\n",
    "print(f\"  Match: {'✓' if len(train_images) == len(train_annotations) else '✗'}\")\n",
    "\n",
    "print(f\"\\nValidation Set:\")\n",
    "print(f\"  Images:      {len(val_images)}\")\n",
    "print(f\"  Annotations: {len(val_annotations)}\")\n",
    "print(f\"  Match: {'✓' if len(val_images) == len(val_annotations) else '✗'}\")\n",
    "\n",
    "print(f\"\\nTotal Dataset:\")\n",
    "print(f\"  Images:      {len(train_images) + len(val_images)}\")\n",
    "print(f\"  Annotations: {len(train_annotations) + len(val_annotations)}\")\n",
    "\n",
    "# Calculate split percentages\n",
    "total = len(train_images) + len(val_images)\n",
    "train_pct = (len(train_images) / total) * 100\n",
    "val_pct = (len(val_images) / total) * 100\n",
    "\n",
    "print(f\"\\nSplit Distribution:\")\n",
    "print(f\"  Train: {train_pct:.1f}%\")\n",
    "print(f\"  Val:   {val_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125da79d",
   "metadata": {},
   "source": [
    "## 6. Parse Filename Metadata\n",
    "\n",
    "Extract patient information from filenames:\n",
    "- Patient ID\n",
    "- Gender (M/F)\n",
    "- Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58577dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing filename parser:\n",
      "\n",
      "3209-F-073Y1_jpg.rf.b3686ffe92cdefd4f386611cd2115d2b.json\n",
      "  → ID: 3209, Gender: Female, Age: 73\n",
      "3210-M-067Y1_jpg.rf.0ec3a0fe3dc1fa4bf5eb776537218e1d.json\n",
      "  → ID: 3210, Gender: Male, Age: 67\n",
      "N1-Olisthesis-L5-S1-F-34-yrs_jpg.rf.b6327af30c0565330e6256ced406971c.json\n",
      "  → ID: N1, Gender: Female, Age: 34\n"
     ]
    }
   ],
   "source": [
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse patient information from filename.\n",
    "    \n",
    "    Format: XXXX-G-YYYYY_jpg.rf.hash.json\n",
    "    Example: 3209-F-073Y1_jpg.rf.b3686ffe92cdefd4f386611cd2115d2b.json\n",
    "    \n",
    "    Returns:\n",
    "        dict: {patient_id, gender, age} or None if parsing fails\n",
    "    \"\"\"\n",
    "    # Pattern for standard format\n",
    "    pattern = r'(\\d+)-([MF])-(\\d+)Y'\n",
    "    match = re.search(pattern, filename)\n",
    "    \n",
    "    if match:\n",
    "        patient_id = match.group(1)\n",
    "        gender = 'Male' if match.group(2) == 'M' else 'Female'\n",
    "        age = int(match.group(3))\n",
    "        return {\n",
    "            'patient_id': patient_id,\n",
    "            'gender': gender,\n",
    "            'age': age,\n",
    "            'filename': filename\n",
    "        }\n",
    "    \n",
    "    # Alternative pattern for other formats (e.g., N1-Olisthesis-L5-S1-F-34-yrs)\n",
    "    pattern2 = r'([NF]\\d+).*-([MF])-(\\d+)'\n",
    "    match2 = re.search(pattern2, filename)\n",
    "    \n",
    "    if match2:\n",
    "        patient_id = match2.group(1)\n",
    "        gender = 'Male' if match2.group(2) == 'M' else 'Female'\n",
    "        age = int(match2.group(3))\n",
    "        return {\n",
    "            'patient_id': patient_id,\n",
    "            'gender': gender,\n",
    "            'age': age,\n",
    "            'filename': filename\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Test on sample files\n",
    "print(\"Testing filename parser:\\n\")\n",
    "test_filenames = [\n",
    "    '3209-F-073Y1_jpg.rf.b3686ffe92cdefd4f386611cd2115d2b.json',\n",
    "    '3210-M-067Y1_jpg.rf.0ec3a0fe3dc1fa4bf5eb776537218e1d.json',\n",
    "    'N1-Olisthesis-L5-S1-F-34-yrs_jpg.rf.b6327af30c0565330e6256ced406971c.json'\n",
    "]\n",
    "\n",
    "for fn in test_filenames:\n",
    "    parsed = parse_filename(fn)\n",
    "    if parsed:\n",
    "        print(f\"{fn}\")\n",
    "        print(f\"  → ID: {parsed['patient_id']}, Gender: {parsed['gender']}, Age: {parsed['age']}\")\n",
    "    else:\n",
    "        print(f\"{fn} - Could not parse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e116029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 534 files successfully\n",
      "Could not parse 164 files\n",
      "\n",
      "Unparsed files:\n",
      "  - N24-S-64-M_1001_0_jpg.rf.9869bb155aedd993bcd42aa9c1a1688d.json\n",
      "  - PARS_19-3-2021-PNG1_jumbo_jpeg_jpg.rf.09bb684d412fe4a6ba1169bb254096fd.json\n",
      "  - PARS_19-3-2021-PNG1_jumbo_jpeg_jpg.rf.6e8ced3c0904abd189f2e0bacb4d1800.json\n",
      "  - PARS_19-3-2021-PNG1_jumbo_jpeg_jpg.rf.d16024abe18937d7866490c54255cd58.json\n",
      "  - PARS_FRACTURE-PNG_1_jumbo_jpeg_jpg.rf.ca56fe7dcadef7a7976096a6b9011a7c.json\n",
      "\n",
      "Sample of parsed metadata:\n",
      "  patient_id  gender  age                                           filename  \\\n",
      "0       3209  Female   73  3209-F-073Y1_jpg.rf.b3686ffe92cdefd4f386611cd2...   \n",
      "1       3210    Male   67  3210-M-067Y1_jpg.rf.0ec3a0fe3dc1fa4bf5eb776537...   \n",
      "2       3211  Female   34  3211-F-034Y1_jpg.rf.f998ff2b707b284dc4cb96eae9...   \n",
      "3       3213    Male   57  3213-M-057Y1_jpg.rf.a40521ebadddc993939db8bd83...   \n",
      "4       3214  Female   69  3214-F-069Y1_jpg.rf.3dd82f2d5fddbf67bec119ce60...   \n",
      "5       3215    Male   64  3215-M-064Y1_jpg.rf.68d06b7415123e2f644b5576e7...   \n",
      "6       3216  Female   56  3216-F-056Y1_jpg.rf.fe0ef81c4f0fb38dba4f78f9a0...   \n",
      "7       3217  Female   78  3217-F-078Y1_jpg.rf.e6a43bd6a60a82c1da658e9446...   \n",
      "8       3218  Female   48  3218-F-048Y1_jpg.rf.92070e84cf9101864ce577abd3...   \n",
      "9       3219  Female   75  3219-F-075Y1_jpg.rf.60c6c9567234c74805d851148a...   \n",
      "\n",
      "   split  n_boxes  n_keypoints  \n",
      "0  train        8            8  \n",
      "1  train        5            5  \n",
      "2  train        6            6  \n",
      "3  train        7            7  \n",
      "4  train        8            8  \n",
      "5  train        7            7  \n",
      "6  train        6            6  \n",
      "7  train        8            8  \n",
      "8  train        6            6  \n",
      "9  train        8            8  \n"
     ]
    }
   ],
   "source": [
    "# Parse all filenames\n",
    "def parse_all_filenames(annotations, split_name):\n",
    "    \"\"\"\n",
    "    Parse patient metadata from all annotation filenames.\n",
    "    \"\"\"\n",
    "    parsed_data = []\n",
    "    unparsed = []\n",
    "    \n",
    "    for ann in annotations:\n",
    "        parsed = parse_filename(ann['filename'])\n",
    "        if parsed:\n",
    "            parsed['split'] = split_name\n",
    "            parsed['n_boxes'] = len(ann['boxes'])\n",
    "            parsed['n_keypoints'] = len(ann['keypoints'])\n",
    "            parsed_data.append(parsed)\n",
    "        else:\n",
    "            unparsed.append(ann['filename'])\n",
    "    \n",
    "    return parsed_data, unparsed\n",
    "\n",
    "# Parse all annotations\n",
    "train_parsed, train_unparsed = parse_all_filenames(train_annotations, 'train')\n",
    "val_parsed, val_unparsed = parse_all_filenames(val_annotations, 'val')\n",
    "\n",
    "# Create DataFrame\n",
    "metadata_df = pd.DataFrame(train_parsed + val_parsed)\n",
    "\n",
    "print(f\"Parsed {len(metadata_df)} files successfully\")\n",
    "print(f\"Could not parse {len(train_unparsed) + len(val_unparsed)} files\")\n",
    "\n",
    "if train_unparsed or val_unparsed:\n",
    "    print(\"\\nUnparsed files:\")\n",
    "    for fn in (train_unparsed + val_unparsed)[:5]:\n",
    "        print(f\"  - {fn}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample of parsed metadata:\")\n",
    "print(metadata_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20cfd1c",
   "metadata": {},
   "source": [
    "## 7. Analyze Demographics\n",
    "\n",
    "Explore patient demographics from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1dcebaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Demographics:\n",
      "============================================================\n",
      "\n",
      "Gender Distribution:\n",
      "  Female   309 ( 57.9%)\n",
      "  Male     225 ( 42.1%)\n",
      "\n",
      "Age Distribution:\n",
      "  Min:     7 years\n",
      "  Max:     93 years\n",
      "  Mean:    48.1 years\n",
      "  Median:  50.0 years\n",
      "  Std Dev: 18.7 years\n",
      "\n",
      "Demographics by Split:\n",
      "============================================================\n",
      "\n",
      "TRAIN:\n",
      "  Total:  330\n",
      "  Male:   136 (41.2%)\n",
      "  Female: 194 (58.8%)\n",
      "  Avg Age: 47.7 years\n",
      "\n",
      "VAL:\n",
      "  Total:  204\n",
      "  Male:   89 (43.6%)\n",
      "  Female: 115 (56.4%)\n",
      "  Avg Age: 48.8 years\n"
     ]
    }
   ],
   "source": [
    "# Overall statistics\n",
    "print(\"Dataset Demographics:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Gender distribution\n",
    "gender_counts = metadata_df['gender'].value_counts()\n",
    "print(f\"\\nGender Distribution:\")\n",
    "for gender, count in gender_counts.items():\n",
    "    pct = (count / len(metadata_df)) * 100\n",
    "    print(f\"  {gender:8} {count:3d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Age statistics\n",
    "print(f\"\\nAge Distribution:\")\n",
    "print(f\"  Min:     {metadata_df['age'].min()} years\")\n",
    "print(f\"  Max:     {metadata_df['age'].max()} years\")\n",
    "print(f\"  Mean:    {metadata_df['age'].mean():.1f} years\")\n",
    "print(f\"  Median:  {metadata_df['age'].median():.1f} years\")\n",
    "print(f\"  Std Dev: {metadata_df['age'].std():.1f} years\")\n",
    "\n",
    "# By split\n",
    "print(f\"\\nDemographics by Split:\")\n",
    "print(\"=\" * 60)\n",
    "for split in ['train', 'val']:\n",
    "    split_df = metadata_df[metadata_df['split'] == split]\n",
    "    male = len(split_df[split_df['gender'] == 'Male'])\n",
    "    female = len(split_df[split_df['gender'] == 'Female'])\n",
    "    avg_age = split_df['age'].mean()\n",
    "    \n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    print(f\"  Total:  {len(split_df)}\")\n",
    "    print(f\"  Male:   {male} ({male/len(split_df)*100:.1f}%)\")\n",
    "    print(f\"  Female: {female} ({female/len(split_df)*100:.1f}%)\")\n",
    "    print(f\"  Avg Age: {avg_age:.1f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209a899",
   "metadata": {},
   "source": [
    "**Important Note**: \n",
    "- **Total training annotations**: 494 (including all files)\n",
    "- **Training files with parseable demographics**: 330 (66.8%)\n",
    "- **Training files without parseable demographics**: 164 (33.2%)\n",
    "\n",
    "The 164 files without parseable demographics have filenames like \"Screenshot-...\", \"PARS_...\", etc. that don't contain patient ID, gender, or age information in the standard format. These files are still valid annotations and will be used for training, but demographic analysis is limited to the 534 files (330 train + 204 val) with parseable filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71044bcb",
   "metadata": {},
   "source": [
    "## 8. Visualize Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e537cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/figures/demographics_overview.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rp/s8pcnsl15jzbb0w87z166p3w0000gn/T/ipykernel_72644/880600224.py:45: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Create demographic visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Gender distribution pie chart\n",
    "ax1 = axes[0, 0]\n",
    "gender_counts.plot(kind='pie', ax=ax1, autopct='%1.1f%%', colors=['#FF6B6B', '#4ECDC4'])\n",
    "ax1.set_ylabel('')\n",
    "ax1.set_title('Gender Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Age distribution histogram\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(metadata_df['age'], bins=20, edgecolor='black', alpha=0.7, color='#95E1D3')\n",
    "ax2.axvline(metadata_df['age'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {metadata_df[\"age\"].mean():.1f}')\n",
    "ax2.axvline(metadata_df['age'].median(), color='blue', linestyle='--', linewidth=2, label=f'Median: {metadata_df[\"age\"].median():.1f}')\n",
    "ax2.set_xlabel('Age (years)', fontsize=12)\n",
    "ax2.set_ylabel('Count', fontsize=12)\n",
    "ax2.set_title('Age Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Gender by split\n",
    "ax3 = axes[1, 0]\n",
    "split_gender = metadata_df.groupby(['split', 'gender']).size().unstack()\n",
    "split_gender.plot(kind='bar', ax=ax3, color=['#FF6B6B', '#4ECDC4'])\n",
    "ax3.set_xlabel('Split', fontsize=12)\n",
    "ax3.set_ylabel('Count', fontsize=12)\n",
    "ax3.set_title('Gender Distribution by Split', fontsize=14, fontweight='bold')\n",
    "ax3.set_xticklabels(['Train', 'Val'], rotation=0)\n",
    "ax3.legend(title='Gender')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Age boxplot by gender\n",
    "ax4 = axes[1, 1]\n",
    "metadata_df.boxplot(column='age', by='gender', ax=ax4, patch_artist=True,\n",
    "                     boxprops=dict(facecolor='lightblue', alpha=0.7))\n",
    "ax4.set_xlabel('Gender', fontsize=12)\n",
    "ax4.set_ylabel('Age (years)', fontsize=12)\n",
    "ax4.set_title('Age Distribution by Gender', fontsize=14, fontweight='bold')\n",
    "plt.suptitle('')  # Remove default title\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'demographics_overview.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"✓ Saved: {FIGURES_DIR / 'demographics_overview.png'}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec7434c",
   "metadata": {},
   "source": [
    "## 9. Analyze Annotation Completeness\n",
    "\n",
    "Check if all images have complete annotations (4 vertebrae)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c8a429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation Completeness Analysis:\n",
      "============================================================\n",
      "\n",
      "Training Set:\n",
      "  Complete (4 vertebrae): 34 / 494 (6.9%)\n",
      "  Incomplete:             460\n",
      "\n",
      "Validation Set:\n",
      "  Complete (4 vertebrae): 1 / 204 (0.5%)\n",
      "  Incomplete:             203\n",
      "\n",
      "Overall:\n",
      "  Complete:   35 / 698 (5.0%)\n",
      "  Incomplete: 663\n",
      "\n",
      "Incomplete annotations found:\n",
      "  - 3209-F-073Y1_jpg.rf.b3686ffe92cdefd4f386611cd2115d2b.json: 8 boxes, 8 keypoint sets\n",
      "  - 3210-M-067Y1_jpg.rf.0ec3a0fe3dc1fa4bf5eb776537218e1d.json: 5 boxes, 5 keypoint sets\n",
      "  - 3211-F-034Y1_jpg.rf.f998ff2b707b284dc4cb96eae9df23fa.json: 6 boxes, 6 keypoint sets\n",
      "  - 3213-M-057Y1_jpg.rf.a40521ebadddc993939db8bd83cae125.json: 7 boxes, 7 keypoint sets\n",
      "  - 3214-F-069Y1_jpg.rf.3dd82f2d5fddbf67bec119ce60f74162.json: 8 boxes, 8 keypoint sets\n",
      "  - 3215-M-064Y1_jpg.rf.68d06b7415123e2f644b5576e78eb6b6.json: 7 boxes, 7 keypoint sets\n",
      "  - 3216-F-056Y1_jpg.rf.fe0ef81c4f0fb38dba4f78f9a0bbcc2e.json: 6 boxes, 6 keypoint sets\n",
      "  - 3217-F-078Y1_jpg.rf.e6a43bd6a60a82c1da658e94463b3d42.json: 8 boxes, 8 keypoint sets\n",
      "  - 3218-F-048Y1_jpg.rf.92070e84cf9101864ce577abd3889e3a.json: 6 boxes, 6 keypoint sets\n",
      "  - 3219-F-075Y1_jpg.rf.60c6c9567234c74805d851148a38516d.json: 8 boxes, 8 keypoint sets\n",
      "  - 3220-M-022Y1_jpg.rf.51674f2a090504d1c124ae372b3c69b7.json: 7 boxes, 7 keypoint sets\n",
      "  - 3221-M-042Y1_jpg.rf.7812367fe7ba48e25f791ec97497e5f3.json: 7 boxes, 7 keypoint sets\n",
      "  - 3223-M-035Y1_jpg.rf.20dcc1cbd790615b8b5ada3847219b48.json: 7 boxes, 7 keypoint sets\n",
      "  - 3224-M-018Y1_jpg.rf.a32a3aabe396592b3138d0d3d6579309.json: 7 boxes, 7 keypoint sets\n",
      "  - 3225-F-019Y1_jpg.rf.780a7c9b193a804439313ae56ba2a04f.json: 8 boxes, 8 keypoint sets\n",
      "  - 3226-M-075Y1_jpg.rf.ca8d380e9d98a11de1be79faed9482da.json: 8 boxes, 8 keypoint sets\n",
      "  - 3227-F-068Y1_jpg.rf.83bef73a8c1199ab4c6441972dfd2445.json: 8 boxes, 8 keypoint sets\n",
      "  - 3228-M-046Y1_jpg.rf.928b72d4007da7fe00c9fea1bb935d88.json: 6 boxes, 6 keypoint sets\n",
      "  - 3229-F-052Y1_jpg.rf.17ef9c2f85951beb92d319bacec6c153.json: 8 boxes, 8 keypoint sets\n",
      "  - 3232-F-059Y1_jpg.rf.e64c3ab66ed3652e9b9659705dcf1d0a.json: 6 boxes, 6 keypoint sets\n",
      "  - 3233-F-050Y1_jpg.rf.737683334638810f69ba93cc3dbfac53.json: 7 boxes, 7 keypoint sets\n",
      "  - 3234-F-042Y1_jpg.rf.279b5e7da6cf7479703583e560a0494f.json: 6 boxes, 6 keypoint sets\n",
      "  - 3235-F-066Y1_jpg.rf.86e279c7a3705593308d0746547e1e25.json: 7 boxes, 7 keypoint sets\n",
      "  - 3236-M-018Y1_jpg.rf.633183eacaa567723e2bfc8021a8d0fc.json: 6 boxes, 6 keypoint sets\n",
      "  - 3237-M-061Y1_jpg.rf.9f7fe9d409faaffd4df5b3af8282ab5b.json: 6 boxes, 6 keypoint sets\n",
      "  - 3240-F-057Y1_jpg.rf.ec16e53fc448ad4d3a6ded8925269caa.json: 8 boxes, 8 keypoint sets\n",
      "  - 3241-M-044Y1_jpg.rf.3e5ec2ac5f9e06a10fec4a87d6194b45.json: 6 boxes, 6 keypoint sets\n",
      "  - 3242-F-052Y1_jpg.rf.ad96fe148500fa146b87c042b9f45c9d.json: 7 boxes, 7 keypoint sets\n",
      "  - 3243-F-066Y1_jpg.rf.06de51b2f51c493b99e5f9b02c828b4a.json: 7 boxes, 7 keypoint sets\n",
      "  - 3246-M-051Y1_jpg.rf.5bee1d467f280850218b77dbfdbdfa95.json: 7 boxes, 7 keypoint sets\n",
      "  - 3248-F-048Y1_jpg.rf.018a5763ede76147b32f3f016033e803.json: 8 boxes, 8 keypoint sets\n",
      "  - 3249-F-061Y1_jpg.rf.e3d192ba24da76dce5b587256922e121.json: 6 boxes, 6 keypoint sets\n",
      "  - 3251-F-072Y1_jpg.rf.57cc81ca658b26e3780c354a86665fd1.json: 9 boxes, 9 keypoint sets\n",
      "  - 3252-M-065Y1_jpg.rf.6db59eeac468350ef581b2babc2532d0.json: 7 boxes, 7 keypoint sets\n",
      "  - 3253-M-039Y1_jpg.rf.6cea33dbeb73d6a5e22ca905af13ffde.json: 6 boxes, 6 keypoint sets\n",
      "  - 3254-F-056Y1_jpg.rf.980ae585a7b698509c58796f0d763777.json: 8 boxes, 8 keypoint sets\n",
      "  - 3255-F-061Y1_jpg.rf.cdf702fcb7c71085eef28d4b3988f73e.json: 6 boxes, 6 keypoint sets\n",
      "  - 3258-M-057Y1_jpg.rf.179d3cf150719a64b9e1c229e430c7e1.json: 8 boxes, 8 keypoint sets\n",
      "  - 3265-M-060Y1_jpg.rf.ed0e9d09e8ba00e77eee4c44cf1165c3.json: 7 boxes, 7 keypoint sets\n",
      "  - 3266-M-030Y1_jpg.rf.bd80f9e7283f8cc7b0e33365f95a783c.json: 7 boxes, 7 keypoint sets\n",
      "  - 3267-M-064Y1_jpg.rf.69451bd74cd7f5e37b21590cf21645ed.json: 7 boxes, 7 keypoint sets\n",
      "  - 3268-F-083Y1_jpg.rf.a0c36d96f24f6471537e75a61f1de56f.json: 10 boxes, 10 keypoint sets\n",
      "  - 3269-F-054Y1_jpg.rf.d20c6f6777cce5ceb2ffbcc65315f98e.json: 8 boxes, 8 keypoint sets\n",
      "  - 3271-M-066Y1_jpg.rf.cdcd2f2261d4b2487f20e7653763e7ec.json: 6 boxes, 6 keypoint sets\n",
      "  - 3273-F-040Y1_jpg.rf.2a0ff2d6255cb3a7479fb8938e96bab5.json: 9 boxes, 9 keypoint sets\n",
      "  - 3275-F-057Y1_jpg.rf.17193c7bdab05a516b35093be0aa8950.json: 7 boxes, 7 keypoint sets\n",
      "  - 3276-F-072Y1_jpg.rf.716f0b3313898c4b557a8ed4136e55b8.json: 9 boxes, 9 keypoint sets\n",
      "  - 3277-F-074Y1_jpg.rf.ab9592fa8170f3d4bac1d6b32be15848.json: 8 boxes, 8 keypoint sets\n",
      "  - 3278-F-054Y1_jpg.rf.c72c9946963f494ae964b697abbb5437.json: 7 boxes, 7 keypoint sets\n",
      "  - 3280-F-039Y1_jpg.rf.9766c568db6b502fbb92a0bf7c70af6a.json: 6 boxes, 6 keypoint sets\n",
      "  - 3281-F-076Y1_jpg.rf.698b453d85c520a41e11455858b3b5ff.json: 11 boxes, 11 keypoint sets\n",
      "  - 3282-F-063Y1_jpg.rf.ab215a4a19c382e690e104ae9de286e7.json: 7 boxes, 7 keypoint sets\n",
      "  - 3283-F-027Y1_jpg.rf.67983e6d02eefbfd4f7003e23581413a.json: 7 boxes, 7 keypoint sets\n",
      "  - 3285-F-063Y1_jpg.rf.36a599c7d9ae9498a7c4d70d83b4ad53.json: 8 boxes, 8 keypoint sets\n",
      "  - 3286-F-058Y1_jpg.rf.f34c6557bb399e762e197dcd35d8dadd.json: 7 boxes, 7 keypoint sets\n",
      "  - 3287-M-074Y1_jpg.rf.bb579324deb57a5b4c8ab191137d9b7d.json: 7 boxes, 7 keypoint sets\n",
      "  - 3290-F-046Y1_jpg.rf.9e78ebfd720d13d0515e382753dc360d.json: 9 boxes, 9 keypoint sets\n",
      "  - 3292-F-050Y1_jpg.rf.49f4f5ce34a287766e630334d7e44026.json: 8 boxes, 8 keypoint sets\n",
      "  - 3293-M-026Y1_jpg.rf.e2ad9efa3f497efdf7d89091b4d6b432.json: 7 boxes, 7 keypoint sets\n",
      "  - 3295-F-057Y1_jpg.rf.5f0cba149aa5a500f23a31b66f03a0bd.json: 8 boxes, 8 keypoint sets\n",
      "  - 3296-F-070Y1_jpg.rf.54f55eeb8c42fced0b25587c31253192.json: 6 boxes, 6 keypoint sets\n",
      "  - 3299-M-022Y1_jpg.rf.9ff56ae44308ffb0658b71963d271037.json: 7 boxes, 7 keypoint sets\n",
      "  - 3301-F-058Y1_jpg.rf.ba6cb7c81a4eb420d762209ca5a44fd6.json: 6 boxes, 6 keypoint sets\n",
      "  - 3302-F-076Y1_jpg.rf.6e4afd881f9bac9b0394d2f2c8799d91.json: 8 boxes, 8 keypoint sets\n",
      "  - 3307-F-058Y1_jpg.rf.593a2041e61e025f26332d71c827abc5.json: 8 boxes, 8 keypoint sets\n",
      "  - 3308-F-052Y1_jpg.rf.5c11329eb096a9af017720cd2ee2f92d.json: 8 boxes, 8 keypoint sets\n",
      "  - 3309-F-067Y1_jpg.rf.b51b30073f89b678660e5bcb5929d6a0.json: 8 boxes, 8 keypoint sets\n",
      "  - 3310-F-053Y1_jpg.rf.a1a8e12061d1b47fcb94986319f84975.json: 8 boxes, 8 keypoint sets\n",
      "  - 3311-M-044Y1_jpg.rf.d9178aa710e2a6018f3658fa11013e3c.json: 7 boxes, 7 keypoint sets\n",
      "  - 3312-M-028Y1_jpg.rf.fc8a59b68926445b5720e561498089ee.json: 8 boxes, 8 keypoint sets\n",
      "  - 3314-M-066Y1_jpg.rf.507fc9fbcd7adcb193b4f27080c17767.json: 9 boxes, 9 keypoint sets\n",
      "  - 3317-M-063Y1_jpg.rf.f4332db12f281fddc272af7f3a906383.json: 6 boxes, 6 keypoint sets\n",
      "  - 3319-F-061Y1_jpg.rf.1d5e01d935dd841e587c6cf292f9adc3.json: 8 boxes, 8 keypoint sets\n",
      "  - 3320-F-072Y1_jpg.rf.64484533cf1a83aaf989ed93560ac127.json: 6 boxes, 6 keypoint sets\n",
      "  - 3322-F-073Y1_jpg.rf.2e1064a08f9f5f0929c4496aa09f7a1f.json: 7 boxes, 7 keypoint sets\n",
      "  - 3324-F-053Y1_jpg.rf.effdd40c3955d086ce72fb3ebd783de3.json: 7 boxes, 7 keypoint sets\n",
      "  - 3326-F-010Y1_jpg.rf.09484511d2529f1465a329351e0b3b10.json: 7 boxes, 7 keypoint sets\n",
      "  - 3327-M-024Y1_jpg.rf.47bd1afb51097897051d95d52501ff4d.json: 9 boxes, 9 keypoint sets\n",
      "  - 3331-M-073Y1_jpg.rf.1e2f9aa3ef49922d66d1e21c3c5dc31a.json: 7 boxes, 7 keypoint sets\n",
      "  - 3332-M-026Y1_jpg.rf.47fa9ce53fb158a2934ae7b139bd4025.json: 7 boxes, 7 keypoint sets\n",
      "  - 3334-M-069Y1_jpg.rf.9cf9f27b163386a4143052ab009b3f05.json: 7 boxes, 7 keypoint sets\n",
      "  - 3335-F-026Y1_jpg.rf.2c6a2138af0f1e281add7b09cf3c1237.json: 7 boxes, 7 keypoint sets\n",
      "  - 3336-F-058Y1_jpg.rf.fa9e83b67660939b94f203d97ec51190.json: 8 boxes, 8 keypoint sets\n",
      "  - 3338-M-055Y1_jpg.rf.1f2a9cfbc8c6f5dda027c14aa399d7a7.json: 8 boxes, 8 keypoint sets\n",
      "  - 3339-F-027Y1_jpg.rf.47835ceb097dc6262498a0c8722d9df6.json: 8 boxes, 8 keypoint sets\n",
      "  - 3341-M-085Y1_jpg.rf.de24823d6db6d6d0f71b526405e14a86.json: 8 boxes, 8 keypoint sets\n",
      "  - 3342-F-053Y1_jpg.rf.e8b6a5d34c2d857c0b1f6afa9431e758.json: 8 boxes, 8 keypoint sets\n",
      "  - 3345-F-086Y1_jpg.rf.fd69146209b28ee97702c17c5c62625e.json: 10 boxes, 10 keypoint sets\n",
      "  - 3350-M-061Y1_jpg.rf.6af3d2f44350d8bccf189e56320f1112.json: 7 boxes, 7 keypoint sets\n",
      "  - 3352-M-058Y1_jpg.rf.7b009eb4a56fe4b0fe456f5762389101.json: 8 boxes, 8 keypoint sets\n",
      "  - 3353-F-050Y1_jpg.rf.cdf56de58777fbc78e66ab9c603c72b4.json: 8 boxes, 8 keypoint sets\n",
      "  - 3359-F-035Y1_jpg.rf.fcbffd2df3cf8d0d32e98e9090b6794e.json: 8 boxes, 8 keypoint sets\n",
      "  - 3360-F-073Y1_jpg.rf.efc8476994563b20b628724d0de3d8a1.json: 7 boxes, 7 keypoint sets\n",
      "  - 3362-F-061Y1_jpg.rf.3f344f61df57999b2aaaa2a349382300.json: 8 boxes, 8 keypoint sets\n",
      "  - 3363-F-032Y1_jpg.rf.452be412926530ec3107e8fdf4e8298b.json: 7 boxes, 7 keypoint sets\n",
      "  - 3366-F-070Y1_jpg.rf.33fcd718825274d614221d153863a44c.json: 7 boxes, 7 keypoint sets\n",
      "  - 3369-F-064Y1_jpg.rf.1c5e378ea9b96c57f04bd52616b7e7a2.json: 8 boxes, 8 keypoint sets\n",
      "  - 3370-F-024Y1_jpg.rf.dad9124af720f4b98f0066353eb9160e.json: 7 boxes, 7 keypoint sets\n",
      "  - 3372-M-038Y1_jpg.rf.199013b321454be764ca61f24f2a68fa.json: 8 boxes, 8 keypoint sets\n",
      "  - 3374-F-061Y1_jpg.rf.7bb063caedc0fe3f6d2f0209ffca829d.json: 8 boxes, 8 keypoint sets\n",
      "  - 3378-M-079Y1_jpg.rf.9c6066b88c302d3456a1d6eeed416eb6.json: 7 boxes, 7 keypoint sets\n",
      "  - 3381-M-050Y1_jpg.rf.a40d1f6150b8bb56a54786ffd324cd2f.json: 7 boxes, 7 keypoint sets\n",
      "  - 3384-F-049Y1_jpg.rf.8a1ec906edd02a1845496ed1bc9f92c0.json: 7 boxes, 7 keypoint sets\n",
      "  - 3387-M-067Y1_jpg.rf.17cfb1867d4820f25c4cf24417487dd0.json: 6 boxes, 6 keypoint sets\n",
      "  - 3392-M-020Y1_jpg.rf.1f06a80369720f62d7977f2845ea8488.json: 8 boxes, 8 keypoint sets\n",
      "  - 3393-F-020Y1_jpg.rf.b40876f0952d57496f59181d8ccaa860.json: 10 boxes, 10 keypoint sets\n",
      "  - 3394-M-060Y1_jpg.rf.e53be9da2a81802ef8e6064c4a3e0545.json: 7 boxes, 7 keypoint sets\n",
      "  - 3397-F-048Y1_jpg.rf.155206992b50dc036d3f0825fb39f855.json: 7 boxes, 7 keypoint sets\n",
      "  - 3400-F-078Y1_jpg.rf.9c0aa65480df65425311c0b94a961da1.json: 6 boxes, 6 keypoint sets\n",
      "  - 3402-F-071Y1_jpg.rf.81abb56d2c82d3c6b03a5cfad289f92b.json: 8 boxes, 8 keypoint sets\n",
      "  - 3403-F-022Y1_jpg.rf.fb5aacc5bafd266a58d9afab8cc3f82f.json: 7 boxes, 7 keypoint sets\n",
      "  - 3404-F-084Y1_jpg.rf.e521d4ac43ce1cf5f58b006867c7646b.json: 7 boxes, 7 keypoint sets\n",
      "  - 3405-M-076Y1_jpg.rf.ea8f88f1f24a8b382d1a5df7353f8732.json: 7 boxes, 7 keypoint sets\n",
      "  - 3406-M-063Y1_jpg.rf.50ade9e6360face78835282339e436b8.json: 7 boxes, 7 keypoint sets\n",
      "  - 3408-F-052Y1_jpg.rf.616885a1e6674410b7d1f702f0d11f84.json: 7 boxes, 7 keypoint sets\n",
      "  - 3409-F-062Y1_jpg.rf.524e17c38ec785046d2ef124dd7670e5.json: 7 boxes, 7 keypoint sets\n",
      "  - 3411-F-074Y1_jpg.rf.7d491326fd2eeeb0927b6a74931508b4.json: 8 boxes, 8 keypoint sets\n",
      "  - 3412-F-057Y1_jpg.rf.a2a96d3c3a8f3d13ba8ae63de9b4d895.json: 7 boxes, 7 keypoint sets\n",
      "  - 3413-M-073Y1_jpg.rf.0d4979c1ecdc64adc047ab660c25e3d2.json: 9 boxes, 9 keypoint sets\n",
      "  - 3415-F-051Y1_jpg.rf.53e63bda4446dee25f028160c99b2379.json: 7 boxes, 7 keypoint sets\n",
      "  - 3418-F-060Y1_jpg.rf.dd587c90fba8fbdd48ff5b1a23325c9b.json: 7 boxes, 7 keypoint sets\n",
      "  - 3426-M-055Y1_jpg.rf.18d4e94af596eef19a1e19080e60e765.json: 7 boxes, 7 keypoint sets\n",
      "  - 3427-M-030Y1_jpg.rf.a83c42bd80a84e2d23304e83d52403cd.json: 7 boxes, 7 keypoint sets\n",
      "  - 3428-F-063Y1_jpg.rf.6f8deb708addb06b279b5251760561fa.json: 7 boxes, 7 keypoint sets\n",
      "  - 3429-F-021Y1_jpg.rf.2190c21853bf53a53eadeaa84f29bb1e.json: 7 boxes, 7 keypoint sets\n",
      "  - 3430-M-064Y1_jpg.rf.41deac597ff1d388d8b3b5c31d76d12e.json: 7 boxes, 7 keypoint sets\n",
      "  - 3431-F-053Y1_jpg.rf.5dc6bc3dc4faf53ca3bd692d08f12770.json: 6 boxes, 6 keypoint sets\n",
      "  - 3432-F-057Y1_jpg.rf.1e463d1ede28e837079833f14dcaa0d8.json: 8 boxes, 8 keypoint sets\n",
      "  - 3433-M-038Y1_jpg.rf.0a9ac89dca91ef78dfa9f20f38472569.json: 8 boxes, 8 keypoint sets\n",
      "  - 3435-F-079Y1_jpg.rf.9a2fd1d530aa32b98a2f86fff8acd3be.json: 8 boxes, 8 keypoint sets\n",
      "  - 3436-F-024Y1_jpg.rf.1f9565dbc61f4cbcbff79ae63c504228.json: 8 boxes, 8 keypoint sets\n",
      "  - 3438-M-052Y1_jpg.rf.3826529c07b0e99105b19df03ce381ea.json: 8 boxes, 8 keypoint sets\n",
      "  - 3441-M-066Y1_jpg.rf.28b48c0e86ec95b43cb57ca9a9bd093f.json: 8 boxes, 8 keypoint sets\n",
      "  - 3443-F-078Y1_jpg.rf.664359c9f6e2ce82e88c7dda643fdcbf.json: 10 boxes, 10 keypoint sets\n",
      "  - 3447-F-040Y1_jpg.rf.3e387c3c30fe2e03047ad68ec7cce507.json: 7 boxes, 7 keypoint sets\n",
      "  - 3448-F-057Y1_jpg.rf.681b4279f5eb6c5fab23a88436903243.json: 8 boxes, 8 keypoint sets\n",
      "  - 3451-M-023Y1_jpg.rf.dcbdb60b5db9721bd03a4578049225c7.json: 7 boxes, 7 keypoint sets\n",
      "  - 3452-F-039Y1_jpg.rf.d90b23d90eec567f9bfb4bea32df3b90.json: 7 boxes, 7 keypoint sets\n",
      "  - 3453-M-024Y1_jpg.rf.20d3fa45751983cf31dcc5b793932798.json: 7 boxes, 7 keypoint sets\n",
      "  - 3454-F-073Y1_jpg.rf.4a51be77cf49a06912aecf920cd6875e.json: 7 boxes, 7 keypoint sets\n",
      "  - 3456-F-031Y1_jpg.rf.672bcd91c425fc058426c82ef190f232.json: 7 boxes, 7 keypoint sets\n",
      "  - 3460-M-059Y1_jpg.rf.ff3db5b0a41b644dcda54c3ffb6a1307.json: 8 boxes, 8 keypoint sets\n",
      "  - 3704-M-045Y1_jpg.rf.a597b75130ea766a3ad0dd4c9c682fde.json: 6 boxes, 6 keypoint sets\n",
      "  - 3705-F-071Y1_jpg.rf.44b9fb13246a63a1d2408c20412dfd98.json: 8 boxes, 8 keypoint sets\n",
      "  - 3709-M-007Y1_jpg.rf.b2117d509ce07c5d2d78d44a68b790c2.json: 7 boxes, 7 keypoint sets\n",
      "  - 3710-M-065Y1_jpg.rf.d55cb5242bae0e9b87b13760a33c241a.json: 8 boxes, 8 keypoint sets\n",
      "  - 3711-F-046Y1_jpg.rf.a269214797e50dff633e8796cd701712.json: 5 boxes, 5 keypoint sets\n",
      "  - 3712-M-036Y1_jpg.rf.be2369fcebad61f60dbd9478114a01cf.json: 7 boxes, 7 keypoint sets\n",
      "  - 3713-M-044Y1_jpg.rf.8533ec6690e7ffe7a47b98aec5a0ad3d.json: 7 boxes, 7 keypoint sets\n",
      "  - 3714-F-057Y1_jpg.rf.fc42264fd6bfa09b9ed1ce3438c4452f.json: 7 boxes, 7 keypoint sets\n",
      "  - 3715-F-022Y1_jpg.rf.d4a008fcd237a4a554b1b438d0e3745f.json: 8 boxes, 8 keypoint sets\n",
      "  - 3716-F-051Y1_jpg.rf.8b859602f2c7b7b61ee2d82f638ac663.json: 7 boxes, 7 keypoint sets\n",
      "  - 3718-M-028Y1_jpg.rf.f9c2101870a03bb496e1c8df080616ad.json: 7 boxes, 7 keypoint sets\n",
      "  - 3720-F-065Y1_jpg.rf.7a23cf7c7a837c256532c42c7141fc0a.json: 7 boxes, 7 keypoint sets\n",
      "  - 3721-F-031Y1_jpg.rf.b78f7a6e1f9602afade0272a20aa53ca.json: 7 boxes, 7 keypoint sets\n",
      "  - 3722-F-050Y1_jpg.rf.f3f621e28e94b29d9635328ac5387a78.json: 7 boxes, 7 keypoint sets\n",
      "  - 3724-M-087Y1_jpg.rf.b0c4a0704fdaad13a6cde7517c6401ff.json: 7 boxes, 7 keypoint sets\n",
      "  - 3726-F-057Y1_jpg.rf.2d8fd7978c17abb3ce60721764b2ffda.json: 7 boxes, 7 keypoint sets\n",
      "  - 3727-F-039Y1_jpg.rf.f03d686cd087ad43fb7c2f8d42aa98ae.json: 7 boxes, 7 keypoint sets\n",
      "  - 3731-F-067Y1_jpg.rf.a70706c54dab6198a42aa1ab5a4d2f83.json: 7 boxes, 7 keypoint sets\n",
      "  - 3732-F-067Y1_jpg.rf.d17fd28e7e5b450c7bcefa73f42e1ec9.json: 9 boxes, 9 keypoint sets\n",
      "  - 3733-F-059Y1_jpg.rf.4aca4cf7b3a9999490b614b0269ead26.json: 6 boxes, 6 keypoint sets\n",
      "  - 3734-M-072Y1_jpg.rf.2ff02288b67cbeff6230df87f2845049.json: 5 boxes, 5 keypoint sets\n",
      "  - 3736-F-053Y1_jpg.rf.416d59c24ab098416c08fdd5796233fd.json: 6 boxes, 6 keypoint sets\n",
      "  - 3740-F-070Y1_jpg.rf.6aa59d545e71014dfec4acd214d2191a.json: 5 boxes, 5 keypoint sets\n",
      "  - 3741-F-057Y1_jpg.rf.7e7519ed7ee22639f1e7720ddceff403.json: 6 boxes, 6 keypoint sets\n",
      "  - 3742-F-046Y1_jpg.rf.cb4defad9930886d5dca6e102d70ffc0.json: 8 boxes, 8 keypoint sets\n",
      "  - 3744-M-017Y1_jpg.rf.3c9b8f2e42d20f0ee5cd7c534ccf29a9.json: 6 boxes, 6 keypoint sets\n",
      "  - 3746-M-035Y1_jpg.rf.c78b1e55bb20afe672b1973061f9f6d8.json: 7 boxes, 7 keypoint sets\n",
      "  - 3747-F-052Y1_jpg.rf.22449402a757283a7f973954510562a8.json: 7 boxes, 7 keypoint sets\n",
      "  - 3750-M-026Y1_jpg.rf.190b9dd6aa0c3ee5f80c7fcf6017a325.json: 6 boxes, 6 keypoint sets\n",
      "  - 3752-M-054Y1_jpg.rf.e0269c00082b928a902320cd51ac861d.json: 6 boxes, 6 keypoint sets\n",
      "  - 3753-F-049Y1_jpg.rf.bd2f74a48154523773539bfce964388a.json: 6 boxes, 6 keypoint sets\n",
      "  - 3760-F-038Y1_jpg.rf.b017ddaef1b875f7dd008c956d4c6cfe.json: 6 boxes, 6 keypoint sets\n",
      "  - 3761-F-027Y1_jpg.rf.b2ac6300a3f9c07173edbb52e5d89ab6.json: 8 boxes, 8 keypoint sets\n",
      "  - 3762-F-055Y1_jpg.rf.e6d0b1697a634bdb0dafd5606e12146f.json: 6 boxes, 6 keypoint sets\n",
      "  - 3763-M-038Y1_jpg.rf.51f45868812324984ce04cc8687dfadd.json: 6 boxes, 6 keypoint sets\n",
      "  - 3764-M-054Y1_jpg.rf.9670fda89126ad6a3367bd4868f343c9.json: 7 boxes, 7 keypoint sets\n",
      "  - 3768-M-064Y1_jpg.rf.b68fd6da7558d28d22186bee11c6db63.json: 6 boxes, 6 keypoint sets\n",
      "  - 3773-F-015Y1_jpg.rf.68e4ae3d47aed0708138173dd5095cba.json: 7 boxes, 7 keypoint sets\n",
      "  - 3779-F-045Y1_jpg.rf.1dbd3008926111537ccf14a80191aeee.json: 7 boxes, 7 keypoint sets\n",
      "  - 3784-M-023Y1_jpg.rf.a7c89a4aae0556ea1563c6627fedd467.json: 5 boxes, 5 keypoint sets\n",
      "  - 3789-F-033Y1_jpg.rf.83333d1cdb0446c49363311efe738110.json: 6 boxes, 6 keypoint sets\n",
      "  - 3790-F-040Y1_jpg.rf.9bbdf29157849e84a05fbed9a0363a60.json: 6 boxes, 6 keypoint sets\n",
      "  - 3792-F-020Y1_jpg.rf.92bd7d3ab77f43971a51011d4319a2e1.json: 6 boxes, 6 keypoint sets\n",
      "  - 3800-F-021Y1_jpg.rf.c105c067a7be2f80cbb102817662ec6f.json: 6 boxes, 6 keypoint sets\n",
      "  - 3808-F-065Y1_jpg.rf.2059d6a7c7be5936136cd11524be2ef8.json: 6 boxes, 6 keypoint sets\n",
      "  - 3811-M-021Y1_jpg.rf.4614dd14c8786081a85f48722d4af4bc.json: 6 boxes, 6 keypoint sets\n",
      "  - 3821-M-025Y1_jpg.rf.fa43f962c8f47fa9b3d17e187936c12c.json: 8 boxes, 8 keypoint sets\n",
      "  - 3832-F-037Y1_jpg.rf.74a1b3c05d037bd202ef3248c71e2ffd.json: 6 boxes, 6 keypoint sets\n",
      "  - 3835-F-017Y1_jpg.rf.6028d1da9ae10a0705cd574c26bd3773.json: 7 boxes, 7 keypoint sets\n",
      "  - 3844-M-044Y1_jpg.rf.0247c697b81686c4a3b4424b78cf51d0.json: 6 boxes, 6 keypoint sets\n",
      "  - 3846-M-043Y1_jpg.rf.26598242e6f0fe95e2088ba3a614cc3d.json: 6 boxes, 6 keypoint sets\n",
      "  - 3847-F-042Y1_jpg.rf.079b45bdf5a022db9dd15603c0a29e79.json: 7 boxes, 7 keypoint sets\n",
      "  - 3850-M-072Y1_jpg.rf.8facb8a1d47611ff1e7c966ed7791012.json: 7 boxes, 7 keypoint sets\n",
      "  - 3864-M-022Y1_jpg.rf.8ce5b4ef05c24fa1330625dbea4338b0.json: 6 boxes, 6 keypoint sets\n",
      "  - 3869-M-024Y1_jpg.rf.4f7d77f8ecb66a20acb6701b75a023f3.json: 6 boxes, 6 keypoint sets\n",
      "  - 3870-F-060Y1_jpg.rf.9cd781c02a46d552feb979bf2505f789.json: 7 boxes, 7 keypoint sets\n",
      "  - 3871-M-066Y1_jpg.rf.2e8730f4a09834b84b423a2da89e41ed.json: 9 boxes, 9 keypoint sets\n",
      "  - 3876-M-029Y1_jpg.rf.295c683595e3dee797e51280e522f9a0.json: 7 boxes, 7 keypoint sets\n",
      "  - 3884-M-077Y1_jpg.rf.e665c5bc1de1c83573aca3a7dbedfc3a.json: 7 boxes, 7 keypoint sets\n",
      "  - 3885-M-032Y1_jpg.rf.22cf1db2e25f58f7dd88306105097fca.json: 5 boxes, 5 keypoint sets\n",
      "  - 3887-F-021Y1_jpg.rf.078aeae83dbc682d25c8c04b7a95f20e.json: 7 boxes, 7 keypoint sets\n",
      "  - 3894-M-048Y1_jpg.rf.8400cdd6b4463e9aa550447c3fac57c6.json: 6 boxes, 6 keypoint sets\n",
      "  - 3899-F-072Y1_jpg.rf.7f9f29a818e290ce2bdeb1d24b155824.json: 7 boxes, 7 keypoint sets\n",
      "  - 3903-F-062Y1_jpg.rf.7f756490affc4828219cfb1af64ba659.json: 6 boxes, 6 keypoint sets\n",
      "  - 3913-F-026Y1_jpg.rf.6497202da6ce5855c130d97f6cdadfd0.json: 6 boxes, 6 keypoint sets\n",
      "  - 3915-M-063Y1_jpg.rf.6d643c5d7f86e8e970e8bae7cafb3db5.json: 6 boxes, 6 keypoint sets\n",
      "  - 3916-F-058Y1_jpg.rf.644c0a1396a7373479ecd8de4652c41b.json: 6 boxes, 6 keypoint sets\n",
      "  - 3917-M-066Y1_jpg.rf.3ff2f73d49ca27ba4131b28932128284.json: 8 boxes, 8 keypoint sets\n",
      "  - 3918-F-050Y1_jpg.rf.9a167360cfe95ce82e53e5eed44ad744.json: 8 boxes, 8 keypoint sets\n",
      "  - 3919-F-059Y1_jpg.rf.618877191d0be07e8c5ca057da9e49ec.json: 6 boxes, 6 keypoint sets\n",
      "  - 3920-M-021Y1_jpg.rf.0e863b31b66a83dd176692d8638facac.json: 7 boxes, 7 keypoint sets\n",
      "  - 3921-M-050Y1_jpg.rf.dc2588b4d530c3c4594e2c6de4e0390b.json: 7 boxes, 7 keypoint sets\n",
      "  - 3922-F-054Y1_jpg.rf.64ff45e7553ede0a2adca13ef2638445.json: 5 boxes, 5 keypoint sets\n",
      "  - 3924-F-053Y1_jpg.rf.e6d0d52d8543882487d286b94729ac38.json: 5 boxes, 5 keypoint sets\n",
      "  - 3926-M-042Y1_jpg.rf.6573d7873a5ca7a5a996fc88b288bdbc.json: 6 boxes, 6 keypoint sets\n",
      "  - 3929-F-054Y1_jpg.rf.fe72cadc4033584e22b88863d7a57c1e.json: 6 boxes, 6 keypoint sets\n",
      "  - 3930-M-020Y1_jpg.rf.58b7f26c2f40c1f71255e6554b6c1464.json: 5 boxes, 5 keypoint sets\n",
      "  - 3938-F-028Y1_jpg.rf.ae7e702b993cef6ca8f0b85e1068bdd1.json: 6 boxes, 6 keypoint sets\n",
      "  - 3939-F-027Y1_jpg.rf.b267d6e15036babad6dada73452bcc88.json: 5 boxes, 5 keypoint sets\n",
      "  - 3942-M-053Y1_jpg.rf.78278f89bb22ec572a283464eb5bf960.json: 6 boxes, 6 keypoint sets\n",
      "  - 3948-F-021Y1_jpg.rf.62c9b922c23e3e192a8b4afdfa1f2dff.json: 6 boxes, 6 keypoint sets\n",
      "  - 3953-M-021Y1_jpg.rf.e4f27876fbd73af3dc3bfaf925c19fa5.json: 8 boxes, 8 keypoint sets\n",
      "  - 3959-M-035Y1_jpg.rf.50127462ea3053386335d112b382027c.json: 6 boxes, 6 keypoint sets\n",
      "  - 3960-F-060Y1_jpg.rf.2a5a35795cbe2a1a5587349cb3da0803.json: 6 boxes, 6 keypoint sets\n",
      "  - 3964-M-024Y1_jpg.rf.0aa74f0038c049696ea8cfc14dd06537.json: 6 boxes, 6 keypoint sets\n",
      "  - 3967-F-043Y1_jpg.rf.4135a03eb984e3113e2e9ae5112d5d3b.json: 7 boxes, 7 keypoint sets\n",
      "  - 3969-M-043Y1_jpg.rf.6ad58ee2618d2d049f8589791982bbc3.json: 6 boxes, 6 keypoint sets\n",
      "  - 3973-M-068Y1_jpg.rf.947c610ead597b36a1ab31fe0172c1a3.json: 5 boxes, 5 keypoint sets\n",
      "  - 3991-M-021Y1_jpg.rf.91bd234482756d7d91122d97d2c2818c.json: 7 boxes, 7 keypoint sets\n",
      "  - 3998-M-015Y1_jpg.rf.9e5ab6b4b9d3f42e884f9a98e873ec8f.json: 6 boxes, 6 keypoint sets\n",
      "  - 3999-M-023Y1_jpg.rf.8427c574eaa3c2d8aae7831fd6cabdce.json: 5 boxes, 5 keypoint sets\n",
      "  - 4011-M-055Y1_jpg.rf.2a6752a850bcdb147c5a3e79e26300fa.json: 7 boxes, 7 keypoint sets\n",
      "  - 4012-F-054Y1_jpg.rf.f563991dd79b75f7c2b56cb916ab0e2f.json: 6 boxes, 6 keypoint sets\n",
      "  - 4031-F-067Y1_jpg.rf.fa45e98f31b2202b9e6f1db49334fbde.json: 6 boxes, 6 keypoint sets\n",
      "  - 4032-M-066Y1_jpg.rf.2d2060a77ebcd5d9630aff3ee7543f54.json: 5 boxes, 5 keypoint sets\n",
      "  - 4037-F-034Y1_jpg.rf.11d7a12656092fe3f37b9722c21abf0e.json: 6 boxes, 6 keypoint sets\n",
      "  - 4039-M-027Y1_jpg.rf.2cf8fabc71f0fa45be4bedd52873f6b9.json: 6 boxes, 6 keypoint sets\n",
      "  - 4064-M-063Y1_jpg.rf.d387a049a23f1e9751e3a57f2fbda738.json: 6 boxes, 6 keypoint sets\n",
      "  - 4072-F-020Y1_jpg.rf.d6f65dfc78f3d82b2106b258d36fca3e.json: 6 boxes, 6 keypoint sets\n",
      "  - 4074-M-032Y1_jpg.rf.604ad343ba37b3904ca7331fe930188a.json: 6 boxes, 6 keypoint sets\n",
      "  - 4075-F-028Y1_jpg.rf.75bfbedfedfdf1f2bc2397ce7f96cb0a.json: 5 boxes, 5 keypoint sets\n",
      "  - 4078-F-043Y1_jpg.rf.bd3f304cb4088ac00e039dd1d966a366.json: 5 boxes, 5 keypoint sets\n",
      "  - 4080-M-067Y1_jpg.rf.e623a09e122f808bfaa0c10d4669eeac.json: 5 boxes, 5 keypoint sets\n",
      "  - 4109-F-035Y1_jpg.rf.b4bcf3c96ca78b2119ea798923f1a859.json: 6 boxes, 6 keypoint sets\n",
      "  - 4110-F-054Y1_jpg.rf.fcdd41c2839e8b4cc6dbaea43e2098d6.json: 6 boxes, 6 keypoint sets\n",
      "  - 4111-M-045Y1_jpg.rf.e1806bb875f93f800738f345879dba46.json: 6 boxes, 6 keypoint sets\n",
      "  - 4112-M-030Y1_jpg.rf.9fde934bc1a3e262c2db3adc45f9a139.json: 5 boxes, 5 keypoint sets\n",
      "  - 4114-M-050Y1_jpg.rf.6471706c7f2ceea7d637a043416bca04.json: 6 boxes, 6 keypoint sets\n",
      "  - 4116-F-055Y1_jpg.rf.08a20cfd155f70b67ab1911bc4144cf7.json: 5 boxes, 5 keypoint sets\n",
      "  - 4117-M-033Y1_jpg.rf.5ad80b4eeb66102710c751a02ae45e68.json: 6 boxes, 6 keypoint sets\n",
      "  - 4123-F-022Y1_jpg.rf.b386823da1e74aa55306fdeb2e807c0a.json: 6 boxes, 6 keypoint sets\n",
      "  - 4142-M-046Y1_jpg.rf.aba02d73b87c4a5d79e2569a8cd1f755.json: 6 boxes, 6 keypoint sets\n",
      "  - 4156-M-043Y1_jpg.rf.511a88f2a64788f5c03458271ff3bb18.json: 7 boxes, 7 keypoint sets\n",
      "  - 4159-F-036Y1_jpg.rf.bf2fd354a4e72caa293bccb9ede19a3a.json: 5 boxes, 5 keypoint sets\n",
      "  - 4160-M-055Y1_jpg.rf.7ac683a472025a3a324301a936576db5.json: 7 boxes, 7 keypoint sets\n",
      "  - 4190-F-037Y1_jpg.rf.7b978df3e42e97e2287126edcaa484df.json: 6 boxes, 6 keypoint sets\n",
      "  - 4200-M-025Y1_jpg.rf.5c589638cb348386b3418c8d41d035e8.json: 5 boxes, 5 keypoint sets\n",
      "  - 4203-F-025Y1_jpg.rf.a3d69f3c5a5177dde97ca66ea8be4200.json: 7 boxes, 7 keypoint sets\n",
      "  - 4205-F-052Y1_jpg.rf.20775610d9fa289ffb587a6479f6acff.json: 6 boxes, 6 keypoint sets\n",
      "  - 4207-F-018Y1_jpg.rf.113d545519fad145391f18d05b27f43a.json: 7 boxes, 7 keypoint sets\n",
      "  - 4208-F-019Y1_jpg.rf.b5a5e2b6627773f78433924ab10e5256.json: 7 boxes, 7 keypoint sets\n",
      "  - 4213-F-063Y1_jpg.rf.e02018473ee7bd4d3ee2e4af9be3213f.json: 8 boxes, 8 keypoint sets\n",
      "  - 4214-M-050Y1_jpg.rf.646efd65cad872ca44f03380a611968c.json: 6 boxes, 6 keypoint sets\n",
      "  - 4216-F-040Y1_jpg.rf.c809d7fce477a33ef3d906eb6b22bb21.json: 5 boxes, 5 keypoint sets\n",
      "  - 4217-F-023Y1_jpg.rf.4bba78cdb3a841b6a673f5616832db47.json: 6 boxes, 6 keypoint sets\n",
      "  - 4220-F-065Y1_jpg.rf.4663d8c0a630f5b3174709d10056577e.json: 5 boxes, 5 keypoint sets\n",
      "  - 4227-M-063Y1_jpg.rf.c273988f25cd936638adf3dedfb88ac0.json: 6 boxes, 6 keypoint sets\n",
      "  - 4228-F-036Y1_jpg.rf.28f9efff93fad432eb8787c6124e693b.json: 6 boxes, 6 keypoint sets\n",
      "  - 4230-M-061Y1_jpg.rf.f65af9abb2c067343e5b11888dae948e.json: 7 boxes, 7 keypoint sets\n",
      "  - 4231-F-055Y1_jpg.rf.f3bd02f3d03c265f8fcc2991a6dba9d3.json: 7 boxes, 7 keypoint sets\n",
      "  - 4239-M-032Y1_jpg.rf.5b2ab81ebc6a62b6a2d7be9275d9b598.json: 6 boxes, 6 keypoint sets\n",
      "  - 4241-F-021Y1_jpg.rf.8b7e7e408d0ce22d8954ff1cf9995790.json: 6 boxes, 6 keypoint sets\n",
      "  - 4245-F-021Y1_jpg.rf.58c25ce71a47c58f6e08e9c0ec6ecaa2.json: 7 boxes, 7 keypoint sets\n",
      "  - 4246-M-024Y1_jpg.rf.6625ae35981151b941d2318615582ddf.json: 7 boxes, 7 keypoint sets\n",
      "  - 4247-M-030Y1_jpg.rf.bfb4ae4ff0ae45ce47c067e05c100003.json: 7 boxes, 7 keypoint sets\n",
      "  - 4248-M-023Y1_jpg.rf.cb32d8c8970af4c418e3397efcb085ff.json: 6 boxes, 6 keypoint sets\n",
      "  - 4260-M-054Y1_jpg.rf.074ea8732193d0b0befec58f4ebb21c5.json: 7 boxes, 7 keypoint sets\n",
      "  - 4262-F-058Y1_jpg.rf.83cfe63dddfa93ba67419f0b06456211.json: 8 boxes, 8 keypoint sets\n",
      "  - 4263-M-052Y1_jpg.rf.38fb513bf8746b54e10f30ce68f51c30.json: 7 boxes, 7 keypoint sets\n",
      "  - 4264-F-027Y1_jpg.rf.8db83a3edfc41e16dd159f64df9863f1.json: 6 boxes, 6 keypoint sets\n",
      "  - 4266-M-020Y1_jpg.rf.4f6815d3aff324cedf79562e9de7a559.json: 7 boxes, 7 keypoint sets\n",
      "  - 4270-F-052Y1_jpg.rf.ab1f6eeb3a084ba84d249fadb2f37f03.json: 6 boxes, 6 keypoint sets\n",
      "  - 4279-M-064Y1_jpg.rf.4ebc878ca521150ebaf2acf0b4d7b3dd.json: 5 boxes, 5 keypoint sets\n",
      "  - 4282-M-028Y1_jpg.rf.064e5edc8543440996f96427b185c57d.json: 7 boxes, 7 keypoint sets\n",
      "  - 4283-F-038Y1_jpg.rf.754d07e8cb486df7652e8693c9d1453c.json: 8 boxes, 8 keypoint sets\n",
      "  - 4285-F-020Y1_jpg.rf.57cfc09f7ed074d324efde5e17e748c8.json: 6 boxes, 6 keypoint sets\n",
      "  - 4287-M-010Y1_jpg.rf.127d75c8fa228a27a2fa3e1f22995124.json: 6 boxes, 6 keypoint sets\n",
      "  - 4300-F-042Y1_jpg.rf.de7c71cbbe66fc24979c514af8d89410.json: 5 boxes, 5 keypoint sets\n",
      "  - 4301-M-017Y1_jpg.rf.6c887a89933e4a02237c0ff671997d89.json: 6 boxes, 6 keypoint sets\n",
      "  - 4302-M-077Y1_jpg.rf.2b6171fd1fdc4714d4fe8f2985ef46ad.json: 7 boxes, 7 keypoint sets\n",
      "  - 4309-M-030Y1_jpg.rf.a779f00a22d8c0acb2a57ad992727213.json: 7 boxes, 7 keypoint sets\n",
      "  - 4318-F-021Y1_jpg.rf.e9ae899c0f8304fd65e078d556bdeb2e.json: 7 boxes, 7 keypoint sets\n",
      "  - 4322-M-051Y1_jpg.rf.4ad43874a78ce2519d8ff9f57e5cf0e1.json: 6 boxes, 6 keypoint sets\n",
      "  - 4324-M-030Y1_jpg.rf.b2bd59320812dcce0dec9f1cdb9249ac.json: 7 boxes, 7 keypoint sets\n",
      "  - 4326-F-044Y1_jpg.rf.7d240ab6297e48a6958c2ba21b6026bf.json: 6 boxes, 6 keypoint sets\n",
      "  - N1-Olisthesis-L5-S1-F-34-yrs_jpg.rf.b6327af30c0565330e6256ced406971c.json: 6 boxes, 6 keypoint sets\n",
      "  - N10-Olisthesis-L4-5-F-35-Yrs_jpg.rf.a27cca57315bfe69793fffdc823bce25.json: 6 boxes, 6 keypoint sets\n",
      "  - N11-Olisthesis-L4-5-M-48-Yrs_jpg.rf.b6a3ef5244e609fdfcd899058f74ec0f.json: 6 boxes, 6 keypoint sets\n",
      "  - N12-Olisthesis-L5-S1-M-20-Yrs_jpg.rf.15870f7cd415b0a6596a0769f78df316.json: 8 boxes, 8 keypoint sets\n",
      "  - N13-Olisthesis-L4-5-F-60-yrs_jpg.rf.7a68431af0201deb0afd97a3e9695dab.json: 9 boxes, 9 keypoint sets\n",
      "  - N14-Olisthesis-L4-5-M-48-Yrs_jpg.rf.9a749b3ec2b8d316a261e88caf1f8734.json: 8 boxes, 8 keypoint sets\n",
      "  - N15-Olisthesis-L4-5-F-33-Yrs_jpg.rf.539153d61fe0ec28442cb51c7ccb67a9.json: 6 boxes, 6 keypoint sets\n",
      "  - N16-Olisthesis-L4-5-F-52-Yrs_jpg.rf.1c4e58111c47e896947e7effb043915f.json: 9 boxes, 9 keypoint sets\n",
      "  - N17-Olisthesis-L4-5-F-58-Yrs_jpg.rf.277ad1fdc76e087b63a444a185fff3ae.json: 7 boxes, 7 keypoint sets\n",
      "  - N18-Olisthesis-L4-5-F-56-Yrs_jpg.rf.3d7a1b0ee31514561d5ab5950f1e43d9.json: 11 boxes, 11 keypoint sets\n",
      "  - N19-Olisthesis-L4-5-M-44-Yrs_jpg.rf.def983254f1a0742edb4b4ec509102e1.json: 6 boxes, 6 keypoint sets\n",
      "  - N2-Olisthesis-L4-5-F-64-yrs_png.rf.50315c45988d025f03947659768fa765.json: 8 boxes, 8 keypoint sets\n",
      "  - N20-Olisthesis-L5-S1-F-34-Yrs_jpg.rf.e5f750284cb83f4788a81da8a672b371.json: 7 boxes, 7 keypoint sets\n",
      "  - N21-Olisthesis-L5-S1-F-54-Yrs_jpg.rf.a20a23df47da8c45dc63181c5a5a31a6.json: 7 boxes, 7 keypoint sets\n",
      "  - N24-Olisthesis-L4-5-F-35-Yrs_jpg.rf.ccee199465847679be3f79cd28339c1b.json: 7 boxes, 7 keypoint sets\n",
      "  - N24-S-64-M_1001_0_jpg.rf.9869bb155aedd993bcd42aa9c1a1688d.json: 8 boxes, 8 keypoint sets\n",
      "  - N25-Olisthesis-L4-5-F-50-Yrs_jpg.rf.edebdd57523dcd436ffbf4c5dd4c84f5.json: 7 boxes, 7 keypoint sets\n",
      "  - N26-Olisthesis-L3-4-F-52-Yrs_jpg.rf.529a8856677b738c2a922b967dfb7271.json: 7 boxes, 7 keypoint sets\n",
      "  - N27-Olisthesis-L4-5-M-61-Yrs_jpg.rf.108cd4e4a56be27d6865e0b43045c0b9.json: 8 boxes, 8 keypoint sets\n",
      "  - N28-Olisthesis-L4-5-M-42-Yrs_jpg.rf.127b8e45253f2aeef0dac149294bddeb.json: 6 boxes, 6 keypoint sets\n",
      "  - N30-Olisthesis-L3-4-and-L4-5-F-48-Yrs_jpg.rf.d20a79e49ec6b7f80d2bc9adcbfdbf87.json: 6 boxes, 6 keypoint sets\n",
      "  - N31-Olisthesis-L5-S1-F-44-Yrs_jpg.rf.278a0a4a2fe95e70c7d7287b15299f91.json: 6 boxes, 6 keypoint sets\n",
      "  - N32-Olisthesis-L4-5-F-65-Yrs_jpg.rf.c50a436d12957e3f900023ee1179036e.json: 6 boxes, 6 keypoint sets\n",
      "  - N33-Olisthesis-L4-5-F-34-Yrs_jpg.rf.82753f342847b775c1d12d9e0466ca06.json: 8 boxes, 8 keypoint sets\n",
      "  - N37-Olisthesis-L5-S1-F-48-Yrs_jpg.rf.ca3eddd8f7736bd8a4c337249705ebe6.json: 5 boxes, 5 keypoint sets\n",
      "  - N38-Olisthesis-L4-5-F-60-Yrs_jpg.rf.22c5f7845325f37b6b4201e00421e74c.json: 7 boxes, 7 keypoint sets\n",
      "  - N39-Olisthesis-L5-S1-F-45-Yrs_jpg.rf.b5e9f837a0700124ebf0cc4a043ce911.json: 9 boxes, 9 keypoint sets\n",
      "  - N40-Olisthesis-L5-S1-M-15-Yrs_jpg.rf.3cb22d8adc514e216550ed4796794ee3.json: 10 boxes, 10 keypoint sets\n",
      "  - N43-Olisthesis-L5-S1-F-26-Yrs_jpg.rf.9d84b6edebeef313c7834a27a91ebee5.json: 7 boxes, 7 keypoint sets\n",
      "  - N44-Olisthesis-L4-5-F-59-Yrs_jpg.rf.a6823ddc95b5fe77fc0b4da37698d931.json: 6 boxes, 6 keypoint sets\n",
      "  - N46-Olisthesis-L4-5-M-63-Yrs_jpg.rf.f4146fd6c5f5c2b420418e49e6c272fb.json: 6 boxes, 6 keypoint sets\n",
      "  - N48-Olisthesis-L3-4-L4-5-L5-S1-F-55-Yrs_jpg.rf.f5159b4f1e1db542fb90aac2e8ec58f3.json: 8 boxes, 8 keypoint sets\n",
      "  - N6-Olisthesis-L4-5-F-60-Yrs_jpg.rf.eba9dea65619af569c1cdab410b779b1.json: 6 boxes, 6 keypoint sets\n",
      "  - N7-Olisthesis-L4-5-F-47-yrs_jpg.rf.9ea0a758a9ac318f42784bc021095ed0.json: 6 boxes, 6 keypoint sets\n",
      "  - PARS_19-3-2021-PNG1_jumbo_jpeg_jpg.rf.09bb684d412fe4a6ba1169bb254096fd.json: 6 boxes, 6 keypoint sets\n",
      "  - PARS_19-3-2021-PNG1_jumbo_jpeg_jpg.rf.6e8ced3c0904abd189f2e0bacb4d1800.json: 7 boxes, 7 keypoint sets\n",
      "  - PARS_19-3-2021-PNG1_jumbo_jpeg_jpg.rf.d16024abe18937d7866490c54255cd58.json: 7 boxes, 7 keypoint sets\n",
      "  - PARS_FRACTURE-PNG_1_jumbo_jpeg_jpg.rf.ca56fe7dcadef7a7976096a6b9011a7c.json: 8 boxes, 8 keypoint sets\n",
      "  - PARS_FRACTURE-PNG_1_jumbo_jpeg_jpg.rf.dc1dbd1ec676d60e520c5012316ae78f.json: 7 boxes, 7 keypoint sets\n",
      "  - Screenshot-2022-07-31-045959_jpg.rf.5e85cc0b3d6886a1fc976fef698cf04a.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-045959_jpg.rf.bda30ea3de9aa3776c4c3ec17bfba46d.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-045959_jpg.rf.f5b76dbbb6cc075b40c48d3ec2484275.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-050311_jpg.rf.a04a0b181e19b19f9002e839b31ef6cf.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050311_jpg.rf.bfabe2fe071d3209534210d7310ca9e5.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-050311_jpg.rf.c83a8e786f322886ee5d023b6620c98c.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-050324_jpg.rf.5f51f43fb734203642fe265bd32cf2d7.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050324_jpg.rf.e4b88e57b4404c267eafdb175462c350.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-050324_jpg.rf.f5cad186538edad342df5d800f4b194f.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-050341_jpg.rf.857a1cbe9a1fac16fe452db7f1faba6b.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050341_jpg.rf.b830ed03f39a1b23b53e440377efba84.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050341_jpg.rf.fa5a507436ac6ac57523bcddc640720e.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050348_jpg.rf.2b82370fe34e4a0a75d3e501a1e08952.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050348_jpg.rf.398dabe72cf4bf8e28d7f48009411de0.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050348_jpg.rf.5a1f013fbad27bb272ce2253cc058ad4.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050419_jpg.rf.41e1024bcfb0de9c953009596179d1fc.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050419_jpg.rf.7ef06faf53cb32f72daa3bfd5ad80f29.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050419_jpg.rf.ad3bddee68c33a6cb159122f27a37070.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050456_jpg.rf.00d3c190714716c73887fbc83feb74d0.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050456_jpg.rf.3ade53aea055835f7afc0434ad479241.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050456_jpg.rf.6d60cd542b5a9e070b5525073b869aa5.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050553_jpg.rf.a39bb0c88bdb3d62d980c4b3eee3406d.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050553_jpg.rf.ab50268291571edcba49fce6be1389eb.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050553_jpg.rf.ce5f8e64bbc9c61e1167a9cd372625bf.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-050922_jpg.rf.9044420793ac2f62cd6e9a52d97d712e.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-050922_jpg.rf.b3a7a9f939945b8338bca8fbcc6cee89.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-050922_jpg.rf.da3cdc907ce22bb68c2ae8a84c9c2c8d.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051000_jpg.rf.2801b8802e1528581bba00f49fe09553.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051000_jpg.rf.446cf08cee18dbc8e806f2915a96684f.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051000_jpg.rf.a8b31b76d0d19b3b3d5559edec93bdcf.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051032_jpg.rf.4371c8918587d74371b641d451a8ac8d.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-051032_jpg.rf.dd9b0230bb88454feec3a318ae5fac13.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-051032_jpg.rf.e815841d374954ac9690d2e8939440ad.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-051048_jpg.rf.09f13e77969340327944108add692124.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-051048_jpg.rf.7b7573f77ed9ab15be68d8639c638382.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-051048_jpg.rf.8b974694e23853cea90d5be63e77614b.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-051102_jpg.rf.1681ab9b9e4ba3567c88edbca4de6e28.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051102_jpg.rf.257ae14ff80baa1d174c17934c1e4923.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051102_jpg.rf.8e54fd80654a928be1ada87cc6331445.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051127_jpg.rf.a5d3652a36b19fe2deb65321655002b4.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-051200_jpg.rf.300c8b9b0c60766abb84973eaa52e961.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051200_jpg.rf.3bde1abcfe26587afe6db378107b0c38.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051200_jpg.rf.73f8ba8ce47294e2c3ce417e9fb64876.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051257_jpg.rf.2248d1d33d54dfb325837f9f45921c80.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051257_jpg.rf.55364be8d14d8614bf92a0df8708973b.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051257_jpg.rf.ba90cef344aa3ef878a7bc7c491c118a.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-051310_jpg.rf.054ad3fc2bd9ebd8fa4273a17876ea7d.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-051310_jpg.rf.2be63aea3d0c1d8a043dffe4c0e8f209.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-051310_jpg.rf.c0d1d64f99935e60d6ba28ab5a4de761.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-053154_jpg.rf.0f8c7e2e3633d99c6d5594ba8ad712a5.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053154_jpg.rf.4a26aeee0b0e55624506564fc4bd60e7.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053154_jpg.rf.923f8fb521b3b4263c3454a88af35e3a.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053204_jpg.rf.514303c72d33b9d7dffbbb67e8e02e08.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-053204_jpg.rf.d53148aba179ad245d011b84adeef66e.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-053347_jpg.rf.48fd44e56dcd6d058560abf3d7f7753b.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053347_jpg.rf.b669d094b02408a1022ed759bee5f3fa.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053347_jpg.rf.d9dd418d4e2fe7030c3edd950eb7468b.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053358_jpg.rf.68cfdc84394a8465579f6d90276cdef8.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-053358_jpg.rf.9fd6f86a714933567df561af1a2e613f.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-053358_jpg.rf.f09e39b97a644b5903874d3e97ba390a.json: 3 boxes, 3 keypoint sets\n",
      "  - Screenshot-2022-07-31-053410_jpg.rf.3a2414b959f583f6731ff3f8d2e48c7c.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-053419_jpg.rf.683498d584efd778e11f7031ee433fae.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-053459_jpg.rf.22de79c4f2bcf71ed14b07ff833fabed.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053459_jpg.rf.33af775b8ffc0bcf1bfb4b98f7727426.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053459_jpg.rf.bb212d0bb2db5abae2c7eac691a18de3.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053552_jpg.rf.6529fffdba5aaeaf18c1cd7501b4d1df.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-053552_jpg.rf.b1465db43afeaa9337281f95da1a132c.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-053605_jpg.rf.00702d2cdfdb6f61d0f13ce5a05b33b8.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053605_jpg.rf.2181242d36ee7f850c4a2e1fdd8174db.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053605_jpg.rf.ad36f242f98dccc3141c3fc1db54451b.json: 6 boxes, 6 keypoint sets\n",
      "  - Screenshot-2022-07-31-053616_jpg.rf.211a172401a5e14267ab575c1c42213e.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-053616_jpg.rf.398e259b6b17454b5390f72358d9f905.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-053616_jpg.rf.a5f068f360a3e076ecd7249df40e41d3.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-053627_jpg.rf.2c5dbbeb9d6d851911a44983dc5f9b42.json: 7 boxes, 7 keypoint sets\n",
      "  - Screenshot-2022-07-31-053627_jpg.rf.5424dd2ecaa619b6dd3ff18765304632.json: 7 boxes, 7 keypoint sets\n",
      "  - Screenshot-2022-07-31-053627_jpg.rf.768b3afeb98b860514d756741d22e61f.json: 7 boxes, 7 keypoint sets\n",
      "  - Screenshot-2022-07-31-053718_jpg.rf.c5a8ffe1da922f55dcd640ac64ced680.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-053718_jpg.rf.e062a3998063b692f6124b1a6c2e86f7.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-053729_jpg.rf.9ba14f2a47b352a58cb15231ca4466ef.json: 5 boxes, 5 keypoint sets\n",
      "  - Screenshot-2022-07-31-053759_jpg.rf.913f6e514ba8af6fe462ea31da7e73d8.json: 3 boxes, 3 keypoint sets\n",
      "  - f2072260f8a9cd2c166e7795f8f28daa_jpg.rf.1f30847b5f011497e03f8fb91484928e.json: 6 boxes, 6 keypoint sets\n",
      "  - f2072260f8a9cd2c166e7795f8f28daa_jpg.rf.a82a6231b9d62db53136e4c4f651499d.json: 5 boxes, 5 keypoint sets\n",
      "  - f2072260f8a9cd2c166e7795f8f28daa_jpg.rf.b904b447c63bdce97c21592551991836.json: 6 boxes, 6 keypoint sets\n",
      "  - f2124aafcd71d5859aed7d1eaefadb3c_jpg.rf.6eca4f579cf54c33cae4e52229c05670.json: 7 boxes, 7 keypoint sets\n",
      "  - f2124aafcd71d5859aed7d1eaefadb3c_jpg.rf.c3f0c19a3b2cbb1d705d3d93b743a4ba.json: 7 boxes, 7 keypoint sets\n",
      "  - f2124aafcd71d5859aed7d1eaefadb3c_jpg.rf.d0f2121889a2cc654eebe586b46786df.json: 7 boxes, 7 keypoint sets\n",
      "  - f4b2d86868673767d8aa682e62aa688d_jpg.rf.27aae2451be7332e82417c004dd2d8c5.json: 7 boxes, 7 keypoint sets\n",
      "  - f4b2d86868673767d8aa682e62aa688d_jpg.rf.7f5baa6ac526e03af6ca97f9969c8c3b.json: 8 boxes, 8 keypoint sets\n",
      "  - f4b2d86868673767d8aa682e62aa688d_jpg.rf.97abd555781123b771a6d831d12a9fc2.json: 6 boxes, 6 keypoint sets\n",
      "  - f4dd04fb042aa0f4f7249283bc3972d8_jpg.rf.b347d3b2776979fcaead1d6768850947.json: 9 boxes, 9 keypoint sets\n",
      "  - f4dd04fb042aa0f4f7249283bc3972d8_jpg.rf.c6fce5314379deee9170b43e0eb276dd.json: 8 boxes, 8 keypoint sets\n",
      "  - f4dd04fb042aa0f4f7249283bc3972d8_jpg.rf.dc8c83544d65c771d5d8d43306a75f04.json: 8 boxes, 8 keypoint sets\n",
      "  - f60e30009a3144202ae88576b003bf83_jpg.rf.4ad094cb90cc8fd05947757f9743b40e.json: 7 boxes, 7 keypoint sets\n",
      "  - f60e30009a3144202ae88576b003bf83_jpg.rf.82bf6f6170a9c7bc2db75702bf45d1c1.json: 8 boxes, 8 keypoint sets\n",
      "  - f60e30009a3144202ae88576b003bf83_jpg.rf.d8b25a003da2607355abcd77090f2693.json: 9 boxes, 9 keypoint sets\n",
      "  - f68ff48e708513a60bc879a5fa567927_jpg.rf.4a46f0aacfa42f78bec42ff42ef64ac8.json: 9 boxes, 9 keypoint sets\n",
      "  - f68ff48e708513a60bc879a5fa567927_jpg.rf.5e56620c71b8515a552df911a4134c57.json: 9 boxes, 9 keypoint sets\n",
      "  - f68ff48e708513a60bc879a5fa567927_jpg.rf.70bc9f5051d4759ee617b07e9559ef7a.json: 6 boxes, 6 keypoint sets\n",
      "  - f93c0b3df3566883f7d48e86c4c424a5_jpg.rf.30a8e4ba077a5cd10270c2b69936a1ac.json: 6 boxes, 6 keypoint sets\n",
      "  - f93c0b3df3566883f7d48e86c4c424a5_jpg.rf.4bfb50f7ae9a8a9eb849c8f74de68638.json: 6 boxes, 6 keypoint sets\n",
      "  - f93c0b3df3566883f7d48e86c4c424a5_jpg.rf.721890cd85fe5eed5b6aec7ab5c59eb4.json: 6 boxes, 6 keypoint sets\n",
      "  - f9a50cfa8d4edbefe7b81a0c8fb2d768_jpg.rf.1f1cb94764d7bdc6d717b2c68041bd05.json: 7 boxes, 7 keypoint sets\n",
      "  - f9a50cfa8d4edbefe7b81a0c8fb2d768_jpg.rf.83d9b1994547e9408d67b6d372d530e2.json: 6 boxes, 6 keypoint sets\n",
      "  - f9a50cfa8d4edbefe7b81a0c8fb2d768_jpg.rf.9a5fa012f77ed087772d548652e1149b.json: 7 boxes, 7 keypoint sets\n",
      "  - f9aeff53dbd35ed208e511684f74709d_jpg.rf.10b5a0c808438e674b831915dc54460e.json: 7 boxes, 7 keypoint sets\n",
      "  - f9aeff53dbd35ed208e511684f74709d_jpg.rf.6e2c87d5313d99072831d25eb00c40a5.json: 6 boxes, 6 keypoint sets\n",
      "  - f9aeff53dbd35ed208e511684f74709d_jpg.rf.807c3cededc1e552280f7a0aec71556f.json: 6 boxes, 6 keypoint sets\n",
      "  - fa7e6851d2d82fc338f9b3914750b9_jumbo_jpeg_jpg.rf.2f040cee9c7c9b0beb316258664e5a34.json: 7 boxes, 7 keypoint sets\n",
      "  - fa7e6851d2d82fc338f9b3914750b9_jumbo_jpeg_jpg.rf.af77abbc7ffd7d88c809833b260d2e63.json: 7 boxes, 7 keypoint sets\n",
      "  - fa7e6851d2d82fc338f9b3914750b9_jumbo_jpeg_jpg.rf.f79398a7e27f0ade737e8354aab81e3d.json: 7 boxes, 7 keypoint sets\n",
      "  - fb6056adf6e37533bfe068af43b72ef6_jpg.rf.2ed3781f27587c736ba4b78fa567913b.json: 8 boxes, 8 keypoint sets\n",
      "  - fb6056adf6e37533bfe068af43b72ef6_jpg.rf.568a88e5a603c0fc1e006062d79d3ba7.json: 9 boxes, 9 keypoint sets\n",
      "  - fb6056adf6e37533bfe068af43b72ef6_jpg.rf.f27df6c4d3f528879380ff2a46763653.json: 10 boxes, 10 keypoint sets\n",
      "  - fc45efa9adecad0e9535e8319212aa51_jpg.rf.56eba60709938cb240f6e24f89df04c6.json: 5 boxes, 5 keypoint sets\n",
      "  - fc45efa9adecad0e9535e8319212aa51_jpg.rf.7a39401f298f3bc03d0a96d645a5b1cc.json: 6 boxes, 6 keypoint sets\n",
      "  - fc45efa9adecad0e9535e8319212aa51_jpg.rf.89625d529aeff3db8205483d0a4a6797.json: 6 boxes, 6 keypoint sets\n",
      "  - fd71e4535c5fd16c32096670c8984022_jpg.rf.34e0e8b9a4f6dac46d771a3b8444ea4f.json: 6 boxes, 6 keypoint sets\n",
      "  - fd71e4535c5fd16c32096670c8984022_jpg.rf.84512efd4feef042368ada6b906cfb72.json: 9 boxes, 9 keypoint sets\n",
      "  - fd71e4535c5fd16c32096670c8984022_jpg.rf.eed779b6260d606451c01f217837cb8b.json: 7 boxes, 7 keypoint sets\n",
      "  - fe9b812f522de8711ae19dffc500472d_jpg.rf.0ca88593e4ec2d8f8e6fb0ba3d670692.json: 9 boxes, 9 keypoint sets\n",
      "  - fe9b812f522de8711ae19dffc500472d_jpg.rf.b24efe7eee8901a92b004f0894f82fd5.json: 9 boxes, 9 keypoint sets\n",
      "  - fe9b812f522de8711ae19dffc500472d_jpg.rf.d999aa96965de7518eee1333cb270747.json: 9 boxes, 9 keypoint sets\n",
      "  - spondylolithesis_jumbo_jpeg_jpg.rf.073dd7a24bfabf1bc52fff2719006a44.json: 7 boxes, 7 keypoint sets\n",
      "  - spondylolithesis_jumbo_jpeg_jpg.rf.887aae70487d845b378693f12686659c.json: 7 boxes, 7 keypoint sets\n",
      "  - 2662-F-044Y1_jpg.rf.d73bdc5b16e4ea2b7f9e749f3f004644.json: 7 boxes, 7 keypoint sets\n",
      "  - 2679-F-016Y1_jpg.rf.8e8d18f58b6e5797b8f92b6bdb55b00c.json: 8 boxes, 8 keypoint sets\n",
      "  - 2695-F-026Y1_jpg.rf.3df07db3271aac57004609a856919a96.json: 6 boxes, 6 keypoint sets\n",
      "  - 2720-M-050Y1_jpg.rf.cf18c74f8cc8411f09cc3fda151c243a.json: 8 boxes, 8 keypoint sets\n",
      "  - 2742-M-073Y1_jpg.rf.738eac69d9540b6d1b0c4d404a31e467.json: 8 boxes, 8 keypoint sets\n",
      "  - 2743-M-027Y1_jpg.rf.8f5bc07327eaf59065df78131b66ca87.json: 9 boxes, 9 keypoint sets\n",
      "  - 2745-F-049Y1_jpg.rf.d4631c1e785795f65509864b5a7ae505.json: 6 boxes, 6 keypoint sets\n",
      "  - 2761-M-065Y1_jpg.rf.9bdd77e73936f0759e69de7634363a1f.json: 7 boxes, 7 keypoint sets\n",
      "  - 2771-F-042Y1_jpg.rf.c1a37a72f3b78f65b84cefa7b8c98493.json: 6 boxes, 6 keypoint sets\n",
      "  - 2772-M-072Y1_jpg.rf.24d20d4ed6952f0423a25109dc09c09f.json: 8 boxes, 8 keypoint sets\n",
      "  - 2775-F-064Y1_jpg.rf.b13a4bd1f0ddaef9b2b0cb5ae94dd998.json: 8 boxes, 8 keypoint sets\n",
      "  - 2776-F-043Y1_jpg.rf.ca7adbc352d495609ee98cc8c29e2009.json: 8 boxes, 8 keypoint sets\n",
      "  - 2781-F-046Y1_jpg.rf.b0fc49bcf567e10b00e76bc38f8953fe.json: 8 boxes, 8 keypoint sets\n",
      "  - 2783-M-046Y1_jpg.rf.2fbd07cb60304d99944cc14e9e689a77.json: 6 boxes, 6 keypoint sets\n",
      "  - 2786-F-053Y1_jpg.rf.2abf57857c425173c26b6c86daa04c50.json: 9 boxes, 9 keypoint sets\n",
      "  - 2787-F-074Y1_jpg.rf.9200583a369eea48194f09b0793d93ee.json: 7 boxes, 7 keypoint sets\n",
      "  - 2791-M-042Y1_jpg.rf.874be456bdf9f3872160e5a871c8f03b.json: 8 boxes, 8 keypoint sets\n",
      "  - 2795-M-052Y1_jpg.rf.db8707ae72128ad174ad57136f01bb88.json: 6 boxes, 6 keypoint sets\n",
      "  - 2797-M-091Y1_jpg.rf.5719697074ec7d7a0844e0460fe9ada2.json: 10 boxes, 10 keypoint sets\n",
      "  - 2805-M-041Y1_jpg.rf.493ab33565ea7e3446740fdbd8f0117b.json: 8 boxes, 8 keypoint sets\n",
      "  - 2808-F-071Y1_jpg.rf.bd3c5fe28cfeac20537f44f339841066.json: 6 boxes, 6 keypoint sets\n",
      "  - 2811-M-055Y1_jpg.rf.20f19cc555fbfc4c4a237e0afc5a46d8.json: 7 boxes, 7 keypoint sets\n",
      "  - 2813-F-082Y1_jpg.rf.483a5c86439dca60ddcfff41482e1422.json: 8 boxes, 8 keypoint sets\n",
      "  - 2815-F-072Y1_jpg.rf.2449d3d97c946173d576bfcb8fa0eec7.json: 7 boxes, 7 keypoint sets\n",
      "  - 2818-M-066Y1_jpg.rf.3a49be38ff2ba1f90d065f53a5ece6f1.json: 9 boxes, 9 keypoint sets\n",
      "  - 2822-F-055Y1_jpg.rf.a7faabe1036d0eb95976d2122bc50a77.json: 6 boxes, 6 keypoint sets\n",
      "  - 2834-M-019Y1_jpg.rf.2f7ec90c7a444cc360f77530553bf18b.json: 7 boxes, 7 keypoint sets\n",
      "  - 2838-M-086Y1_jpg.rf.1c08ae4c1d38fadb7f60d72cd99c02d7.json: 8 boxes, 8 keypoint sets\n",
      "  - 2842-F-066Y1_jpg.rf.d15dbdeb199dce9b834f944469c4abd6.json: 9 boxes, 9 keypoint sets\n",
      "  - 2845-F-057Y1_jpg.rf.c9fab6d6b899ae34f881c79d66cd81ed.json: 6 boxes, 6 keypoint sets\n",
      "  - 2846-M-026Y1_jpg.rf.924960c338a9197257d80b0f406d6b2b.json: 8 boxes, 8 keypoint sets\n",
      "  - 2847-F-068Y1_jpg.rf.9e51e7669eeb6396d68e01b73fdb988f.json: 9 boxes, 9 keypoint sets\n",
      "  - 2848-F-064Y1_jpg.rf.05a235728ae08244dfc6ac39352efb42.json: 7 boxes, 7 keypoint sets\n",
      "  - 2850-F-052Y1_jpg.rf.2fff86e216aa5fa64b4091da1368fce8.json: 7 boxes, 7 keypoint sets\n",
      "  - 2851-F-044Y1_jpg.rf.9833b3af5ce09bdbad850e917dc278d2.json: 8 boxes, 8 keypoint sets\n",
      "  - 2855-F-071Y1_jpg.rf.6b61d45b2cd9b8f6e3133ebe6c43a15a.json: 8 boxes, 8 keypoint sets\n",
      "  - 2856-M-038Y1_jpg.rf.113199926d75baffe39b5077fa2f6b17.json: 7 boxes, 7 keypoint sets\n",
      "  - 2857-F-044Y1_jpg.rf.b2118d28f7f7825165905e2236712449.json: 10 boxes, 10 keypoint sets\n",
      "  - 2859-F-051Y1_jpg.rf.61469ad7211b30021500584e89c35c22.json: 6 boxes, 6 keypoint sets\n",
      "  - 2868-F-042Y1_jpg.rf.c79234fda20da12d7da2346ac64028a7.json: 8 boxes, 8 keypoint sets\n",
      "  - 2870-M-023Y1_jpg.rf.8b0238c3ec8064beb703b7f700bc7b3e.json: 7 boxes, 7 keypoint sets\n",
      "  - 2871-F-080Y1_jpg.rf.7f47d725db9fa667298bdc723b7483f1.json: 9 boxes, 9 keypoint sets\n",
      "  - 2873-M-072Y1_jpg.rf.e4715fb230db674ec10ab70d2c530f8d.json: 7 boxes, 7 keypoint sets\n",
      "  - 2874-F-041Y1_jpg.rf.a23bf23d2ce49fb7023fd2810a18ebe6.json: 7 boxes, 7 keypoint sets\n",
      "  - 2894-F-027Y1_jpg.rf.b17e0f0306d65fab3bb0f385993a8993.json: 7 boxes, 7 keypoint sets\n",
      "  - 2998-M-045Y1_jpg.rf.47f7c46ee7e9d6e766624787a54abe6c.json: 7 boxes, 7 keypoint sets\n",
      "  - 3001-F-021Y1_jpg.rf.5b4025f30c65013e633a6ba77de7fc5b.json: 6 boxes, 6 keypoint sets\n",
      "  - 3011-F-029Y1_jpg.rf.35dfc1a113473cc153b3a6d47c938ac1.json: 6 boxes, 6 keypoint sets\n",
      "  - 3020-F-042Y1_jpg.rf.972d1b4af2fe23901d3c1eb199ae23c4.json: 6 boxes, 6 keypoint sets\n",
      "  - 3027-F-071Y1_jpg.rf.cb78832d111e29d3838f2483fa314182.json: 9 boxes, 9 keypoint sets\n",
      "  - 3039-M-035Y1_jpg.rf.4f9fb5fe03a44de75015afaf698c4b35.json: 7 boxes, 7 keypoint sets\n",
      "  - 3046-F-062Y1_jpg.rf.106891e2350cb13850121149cc41f767.json: 8 boxes, 8 keypoint sets\n",
      "  - 3053-F-052Y1_jpg.rf.4f182b5aaba997cc8c4f9604a5a12c89.json: 7 boxes, 7 keypoint sets\n",
      "  - 3062-M-053Y1_jpg.rf.0d55105b9497263b12a61faba3401b1b.json: 7 boxes, 7 keypoint sets\n",
      "  - 3064-F-071Y1_jpg.rf.5fd4b022403aeede238c75ffbc08d37c.json: 7 boxes, 7 keypoint sets\n",
      "  - 3069-M-067Y1_jpg.rf.1a3f690ad82da6307b41ec03b6df42ef.json: 6 boxes, 6 keypoint sets\n",
      "  - 3070-F-088Y1_jpg.rf.6e65748633cd3709f44dc9c9340897eb.json: 10 boxes, 10 keypoint sets\n",
      "  - 3075-M-074Y1_jpg.rf.747383b0ee83e0022b2a96e044da682c.json: 8 boxes, 8 keypoint sets\n",
      "  - 3083-F-062Y1_jpg.rf.80a7fb85f5c28e3c29e31b1fba0656a6.json: 8 boxes, 8 keypoint sets\n",
      "  - 3087-M-028Y1_jpg.rf.4798e89c411dcac5d42f2522a0d0225e.json: 7 boxes, 7 keypoint sets\n",
      "  - 3090-F-031Y1_jpg.rf.f9b120585d0234b7fbb0db8eb0b134c7.json: 6 boxes, 6 keypoint sets\n",
      "  - 3098-F-034Y1_jpg.rf.28578ff28384080edb60c324b54aad3d.json: 7 boxes, 7 keypoint sets\n",
      "  - 3099-M-036Y1_jpg.rf.83d38dc6ef7a3ddffd1010d869098edf.json: 7 boxes, 7 keypoint sets\n",
      "  - 3100-F-056Y1_jpg.rf.03400ce234be4fc59e6e0793cd4d84db.json: 7 boxes, 7 keypoint sets\n",
      "  - 3101-M-036Y1_jpg.rf.61b7439baf16772104d7349055acf458.json: 6 boxes, 6 keypoint sets\n",
      "  - 3102-F-055Y1_jpg.rf.f5247a01c1e1a6e762621ed01e366041.json: 6 boxes, 6 keypoint sets\n",
      "  - 3103-F-053Y1_jpg.rf.e06c7b656d53ba8ea1c31e5a7bbd0eaf.json: 9 boxes, 9 keypoint sets\n",
      "  - 3104-F-038Y1_jpg.rf.b3c1321f8ddbba03b7817f2be6a2a3a8.json: 10 boxes, 10 keypoint sets\n",
      "  - 3105-F-041Y1_jpg.rf.300f77ec8245025d24a74523d88becd1.json: 7 boxes, 7 keypoint sets\n",
      "  - 3107-F-023Y1_jpg.rf.205295e910241047279e954a96ea6a71.json: 8 boxes, 8 keypoint sets\n",
      "  - 3108-M-069Y1_jpg.rf.3e7487e98bc05e2c34fa2c02368ffca6.json: 6 boxes, 6 keypoint sets\n",
      "  - 3109-F-053Y1_jpg.rf.5d230eff75634ebffa62a6fe2f83593a.json: 9 boxes, 9 keypoint sets\n",
      "  - 3111-F-093Y1_jpg.rf.b8ddf82b2d364182db0a7ab5ad7556b0.json: 7 boxes, 7 keypoint sets\n",
      "  - 3112-F-061Y1_jpg.rf.631b651c99472b4d0a563a586998aa5b.json: 9 boxes, 9 keypoint sets\n",
      "  - 3113-F-041Y1_jpg.rf.f3161552a5bb811ed2e1736652b15d40.json: 8 boxes, 8 keypoint sets\n",
      "  - 3114-F-057Y1_jpg.rf.c3bd3d0d68a7041124ac4f0b5a12636c.json: 7 boxes, 7 keypoint sets\n",
      "  - 3115-M-033Y1_jpg.rf.c8592ff5ca3140aa69f70b0e53f7cd7d.json: 6 boxes, 6 keypoint sets\n",
      "  - 3116-F-080Y1_jpg.rf.4f22126060c65534fb422c8d1ea2674d.json: 7 boxes, 7 keypoint sets\n",
      "  - 3119-F-021Y1_jpg.rf.a471ed75da62c74e7770c1a4e4e38aa2.json: 8 boxes, 8 keypoint sets\n",
      "  - 3120-F-036Y1_jpg.rf.83db910a752b0c2d80246b2793cf4e4e.json: 7 boxes, 7 keypoint sets\n",
      "  - 3122-M-064Y1_jpg.rf.da89c252d7cd38832d3e951ca726f283.json: 7 boxes, 7 keypoint sets\n",
      "  - 3123-F-036Y1_jpg.rf.beecce5767f18f247cddef088df2ec7d.json: 7 boxes, 7 keypoint sets\n",
      "  - 3126-F-045Y1_jpg.rf.ba1cc6ca26db9b637c63c5a6d87a9428.json: 10 boxes, 10 keypoint sets\n",
      "  - 3128-M-025Y1_jpg.rf.687d7738d046a2291ed9f3666056ffbe.json: 7 boxes, 7 keypoint sets\n",
      "  - 3129-M-041Y1_jpg.rf.98fec693d741458ed434587c3af186ec.json: 8 boxes, 8 keypoint sets\n",
      "  - 3130-M-040Y1_jpg.rf.2d5fb946e7c039d9a79ea9eb69077bcc.json: 8 boxes, 8 keypoint sets\n",
      "  - 3131-F-063Y1_jpg.rf.6c6de5cb0c23eddabb3474c025f5e54f.json: 8 boxes, 8 keypoint sets\n",
      "  - 3132-F-024Y1_jpg.rf.4a08d85bcc94ba61a1c4bcef37c5cb1a.json: 6 boxes, 6 keypoint sets\n",
      "  - 3133-M-023Y1_jpg.rf.e0001ee351c9924a561e5eb0554b2bd5.json: 6 boxes, 6 keypoint sets\n",
      "  - 3134-F-078Y1_jpg.rf.42ff8615e9117f100935c9b412683fdb.json: 7 boxes, 7 keypoint sets\n",
      "  - 3135-M-032Y1_jpg.rf.6cecd2b603935d305ef55baf2db59530.json: 7 boxes, 7 keypoint sets\n",
      "  - 3136-M-086Y1_jpg.rf.8b67a363b7f84716c3cb76e316b239a3.json: 8 boxes, 8 keypoint sets\n",
      "  - 3140-F-070Y1_jpg.rf.03092641610b193b031064ed94c74bfd.json: 7 boxes, 7 keypoint sets\n",
      "  - 3141-F-074Y1_jpg.rf.76efc0a1f2f9eabf399b4ae09d2c3381.json: 8 boxes, 8 keypoint sets\n",
      "  - 3142-M-079Y1_jpg.rf.4b5205ead0d27faf2c431599ff662383.json: 7 boxes, 7 keypoint sets\n",
      "  - 3143-F-053Y1_jpg.rf.08ba7f912827a976c3c79a2070f390d3.json: 8 boxes, 8 keypoint sets\n",
      "  - 3145-F-064Y1_jpg.rf.9dbb9610fa4c7c75951d7f84495e6e7c.json: 6 boxes, 6 keypoint sets\n",
      "  - 3147-M-036Y1_jpg.rf.4c814219f38abbcbd66b2d9803dd23c4.json: 6 boxes, 6 keypoint sets\n",
      "  - 3149-F-044Y1_jpg.rf.832f0daae74b95ac8a66d11a9d03a652.json: 8 boxes, 8 keypoint sets\n",
      "  - 3150-F-045Y1_jpg.rf.8951d1c8386d36dca94805eb64dfef2b.json: 6 boxes, 6 keypoint sets\n",
      "  - 3151-F-019Y1_jpg.rf.cb7ff4b8064ebeb716aaffb11cac359c.json: 8 boxes, 8 keypoint sets\n",
      "  - 3153-M-025Y1_jpg.rf.c0a88f39a1dc2114c7427dd1ed9165b3.json: 9 boxes, 9 keypoint sets\n",
      "  - 3154-M-059Y1_jpg.rf.7920ddf942a41c6cd0a777baa866a8cd.json: 6 boxes, 6 keypoint sets\n",
      "  - 3155-F-076Y1_jpg.rf.40ddc2cf20c7d7ca8550a12df4505dc7.json: 11 boxes, 11 keypoint sets\n",
      "  - 3156-M-046Y1_jpg.rf.a14b2c36894714656285c2d0603f9393.json: 7 boxes, 7 keypoint sets\n",
      "  - 3158-F-024Y1_jpg.rf.d6ca1acf8b87baacabbeb39f52956901.json: 7 boxes, 7 keypoint sets\n",
      "  - 3159-M-076Y1_jpg.rf.8b9b034c61bbd1bd0fd8cdc4b97ed53f.json: 8 boxes, 8 keypoint sets\n",
      "  - 3160-F-057Y1_jpg.rf.1f6232c46f5ca78e7186298c7330570e.json: 7 boxes, 7 keypoint sets\n",
      "  - 3162-F-068Y1_jpg.rf.eb1dfcabb56cb34f217a4a6552881727.json: 7 boxes, 7 keypoint sets\n",
      "  - 3164-M-072Y1_jpg.rf.16fac1c5d5396eb584fb1f49b20dfb67.json: 8 boxes, 8 keypoint sets\n",
      "  - 3165-F-060Y1_jpg.rf.dd015dffaff0288f2b89d25dcecd4246.json: 9 boxes, 9 keypoint sets\n",
      "  - 3166-F-069Y1_jpg.rf.6708ff2941941917886ecdc6f5478c22.json: 7 boxes, 7 keypoint sets\n",
      "  - 3167-F-073Y1_jpg.rf.c225a63c40db92eebad922bd35e5d4f0.json: 8 boxes, 8 keypoint sets\n",
      "  - 3169-M-069Y1_jpg.rf.4120ccd1d44842efd62e01810079dd03.json: 8 boxes, 8 keypoint sets\n",
      "  - 3171-F-074Y1_jpg.rf.0dbe8bb4169b38c8cb06030561fa6297.json: 8 boxes, 8 keypoint sets\n",
      "  - 3172-M-063Y1_jpg.rf.b8a95444a7b41bf0b5f5158c0eceda5e.json: 6 boxes, 6 keypoint sets\n",
      "  - 3173-F-064Y1_jpg.rf.151e83f917010e55db854d4b4b5de916.json: 6 boxes, 6 keypoint sets\n",
      "  - 3174-F-078Y1_jpg.rf.7bbd3875104a4c297aed528ca4506a61.json: 10 boxes, 10 keypoint sets\n",
      "  - 3175-M-026Y1_jpg.rf.b655aedf394f0a56aef28bfa0a5f2fe7.json: 7 boxes, 7 keypoint sets\n",
      "  - 3176-F-054Y1_jpg.rf.07ecd214e587950f53f544cafb40a30f.json: 7 boxes, 7 keypoint sets\n",
      "  - 3177-F-076Y1_jpg.rf.1f2675e7dd33e8d139acd431b7f6c409.json: 9 boxes, 9 keypoint sets\n",
      "  - 3178-M-068Y1_jpg.rf.d09c900048351431eb11ffb3748b6dfe.json: 9 boxes, 9 keypoint sets\n",
      "  - 3179-F-047Y1_jpg.rf.8bd18387b803e0bf6674d03f678d1cf1.json: 10 boxes, 10 keypoint sets\n",
      "  - 3180-M-073Y1_jpg.rf.fa69c21d9888b3f7a0b6632dd1ed6d95.json: 7 boxes, 7 keypoint sets\n",
      "  - 3181-F-041Y1_jpg.rf.eb8ce8f28c2accac30548fcb564cde04.json: 8 boxes, 8 keypoint sets\n",
      "  - 3182-M-021Y1_jpg.rf.67487946a0246d436ede6413848e5f36.json: 5 boxes, 5 keypoint sets\n",
      "  - 3184-M-078Y1_jpg.rf.562e9b2d89a8dd864337e02720b7fb79.json: 9 boxes, 9 keypoint sets\n",
      "  - 3185-F-038Y1_jpg.rf.04bd27344c2fa7c58446a4ae989deb91.json: 8 boxes, 8 keypoint sets\n",
      "  - 3186-F-089Y1_jpg.rf.1800d87869be23bd36dc57cd58948314.json: 11 boxes, 11 keypoint sets\n",
      "  - 3187-M-078Y1_jpg.rf.01813f1c0bb211ca1265025cf10fc88d.json: 9 boxes, 9 keypoint sets\n",
      "  - 3189-F-073Y1_jpg.rf.47be58bb0d543d41e6a77aed822e3db8.json: 8 boxes, 8 keypoint sets\n",
      "  - 3190-M-027Y1_jpg.rf.77d1329e4deae1a1283d6375fa38f771.json: 7 boxes, 7 keypoint sets\n",
      "  - 3191-F-088Y1_jpg.rf.7e79ea9555ed1445d5c8c2613f017c32.json: 7 boxes, 7 keypoint sets\n",
      "  - 3192-F-069Y1_jpg.rf.d6f29269f5a833d40de7864cd5371cf4.json: 8 boxes, 8 keypoint sets\n",
      "  - 3193-F-027Y1_jpg.rf.bef6b83ee9b6defbfda30648d39343cd.json: 7 boxes, 7 keypoint sets\n",
      "  - 3195-F-071Y1_jpg.rf.b8c4a0bd466828c8f2ed9bf146b1cb0d.json: 5 boxes, 5 keypoint sets\n",
      "  - 3196-M-061Y1_jpg.rf.087f30305045b6fae92bd3c4722b355b.json: 7 boxes, 7 keypoint sets\n",
      "  - 3197-M-030Y1_jpg.rf.7b327fa8fc705010c109d9ad7c5717d8.json: 7 boxes, 7 keypoint sets\n",
      "  - 3198-M-042Y1_jpg.rf.c564c87ecac0ace88238b3f348ccd840.json: 6 boxes, 6 keypoint sets\n",
      "  - 3200-F-070Y1_jpg.rf.cdf4112e50647ffd53d513efdcf64a1f.json: 8 boxes, 8 keypoint sets\n",
      "  - 3202-F-083Y1_jpg.rf.28cb15e1d92f8c932ab1884535d495e2.json: 7 boxes, 7 keypoint sets\n",
      "  - 3203-F-046Y1_jpg.rf.d22dbe55fa73d803382c7893456bc7df.json: 7 boxes, 7 keypoint sets\n",
      "  - 3204-F-047Y1_jpg.rf.10e2d0ef3596e2db24bd6a3a87a27b21.json: 8 boxes, 8 keypoint sets\n",
      "  - 3206-F-030Y1_jpg.rf.46a0581accf09b68ec55205306fa2fca.json: 6 boxes, 6 keypoint sets\n",
      "  - 3207-F-053Y1_jpg.rf.8c2eba7fdac8665ff445576dd4b695e2.json: 8 boxes, 8 keypoint sets\n",
      "  - 4330-F-056Y1_jpg.rf.09bdf85cafa17515d7119d9044002aea.json: 5 boxes, 5 keypoint sets\n",
      "  - 4332-M-020Y1_jpg.rf.48cc4367223ce56f154629de2df1b537.json: 6 boxes, 6 keypoint sets\n",
      "  - 4333-F-044Y1_jpg.rf.dca7e1ba8269878270de60666df047ad.json: 6 boxes, 6 keypoint sets\n",
      "  - 4336-M-052Y1_jpg.rf.0ef93fe2ca8779895ef464da8363104b.json: 6 boxes, 6 keypoint sets\n",
      "  - 4340-F-051Y1_jpg.rf.be5f155e4527b8321244cfcf91cf42c6.json: 6 boxes, 6 keypoint sets\n",
      "  - 4342-M-027Y1_jpg.rf.63e85a39d33bf542eacb7645d03f169d.json: 6 boxes, 6 keypoint sets\n",
      "  - 4345-M-041Y1_jpg.rf.c7266584211624e7fa3317c97c3ca59b.json: 6 boxes, 6 keypoint sets\n",
      "  - 4351-M-037Y1_jpg.rf.e83dc52f0ff7e89c58a71110c590b11d.json: 6 boxes, 6 keypoint sets\n",
      "  - 4354-M-019Y1_jpg.rf.9f37739be4f7f14d9471730a36cf7fc2.json: 7 boxes, 7 keypoint sets\n",
      "  - 4362-M-054Y1_jpg.rf.fc2afa14a20d963d290984ed2c88eac7.json: 6 boxes, 6 keypoint sets\n",
      "  - 4369-M-032Y1_jpg.rf.57e9b5fdcc7ef5c08ababb39dad48074.json: 5 boxes, 5 keypoint sets\n",
      "  - 4371-F-023Y1_jpg.rf.53879731346f9d4d2790715323c8e46c.json: 6 boxes, 6 keypoint sets\n",
      "  - 4385-F-043Y1_jpg.rf.cd7268165923d85accf546446bec0334.json: 6 boxes, 6 keypoint sets\n",
      "  - 4387-F-023Y1_jpg.rf.8b41a4c8106d0aa918cf70dafa0ae577.json: 7 boxes, 7 keypoint sets\n",
      "  - 4391-F-024Y1_jpg.rf.991a5a314d33334b858744e8655f64e1.json: 6 boxes, 6 keypoint sets\n",
      "  - 4393-M-013Y1_jpg.rf.ee97b31fd35ab3dcebc26880e49e3a1b.json: 7 boxes, 7 keypoint sets\n",
      "  - 4411-M-029Y1_jpg.rf.df88dc86755e19d7e67e614641eb3903.json: 7 boxes, 7 keypoint sets\n",
      "  - 4423-M-057Y1_jpg.rf.799c509a39f7c173933e73347c865aef.json: 7 boxes, 7 keypoint sets\n",
      "  - 4427-M-061Y1_jpg.rf.0c049c5e465545502d33f174c20510a4.json: 6 boxes, 6 keypoint sets\n",
      "  - 4428-M-025Y1_jpg.rf.1f60f9760f44234c659c166629f95660.json: 6 boxes, 6 keypoint sets\n",
      "  - 4439-M-061Y1_jpg.rf.50807e51b28f040907efd1cf161f5280.json: 5 boxes, 5 keypoint sets\n",
      "  - 4442-F-025Y1_jpg.rf.fc8836ec825b7dea7225720906f5b02d.json: 5 boxes, 5 keypoint sets\n",
      "  - 4447-F-022Y1_jpg.rf.cb0fb786edea7c8c1ee3b7d86b86a5df.json: 6 boxes, 6 keypoint sets\n",
      "  - 4449-M-038Y1_jpg.rf.54b9652a89f518cefda1c05bb0337d66.json: 5 boxes, 5 keypoint sets\n",
      "  - 4606-M-021Y1_jpg.rf.22ceec5cee182f16022cad2ddab3b8f6.json: 6 boxes, 6 keypoint sets\n",
      "  - 4611-M-058Y1_jpg.rf.412c72af786dce701fde79bb62238bbb.json: 7 boxes, 7 keypoint sets\n",
      "  - 4612-M-040Y1_jpg.rf.b4b642c33c0dc367158e45637471cd63.json: 6 boxes, 6 keypoint sets\n",
      "  - 4614-M-019Y1_jpg.rf.b48ec1a466b82bbaa27c6ce6bf0f0052.json: 6 boxes, 6 keypoint sets\n",
      "  - 4642-M-043Y1_jpg.rf.38d699d3fd9d046fd6be374b6a553549.json: 6 boxes, 6 keypoint sets\n",
      "  - 4654-M-014Y1_jpg.rf.f8118a60eb045665af8ca23d89c56048.json: 5 boxes, 5 keypoint sets\n",
      "  - 4665-M-030Y1_jpg.rf.43988d3a11687cefb0f8bc88f6919061.json: 7 boxes, 7 keypoint sets\n",
      "  - 4666-F-043Y1_jpg.rf.b8c7f3676438af2df73ed0b0566df32d.json: 5 boxes, 5 keypoint sets\n",
      "  - 4669-F-019Y1_jpg.rf.f1eae38ebb38ae5866903278b49410c2.json: 5 boxes, 5 keypoint sets\n",
      "  - 4670-M-036Y1_jpg.rf.7e6d408595486b9e97bb128c8e3f9412.json: 6 boxes, 6 keypoint sets\n",
      "  - 4672-F-021Y1_jpg.rf.42cff01b1b2a6943c22fbe3947334cc3.json: 6 boxes, 6 keypoint sets\n",
      "  - 4674-M-037Y1_jpg.rf.61cd5a36e48434074634a693629103e9.json: 5 boxes, 5 keypoint sets\n",
      "  - 4678-F-062Y1_jpg.rf.bf8789e36e37717fd852650baf9a8103.json: 6 boxes, 6 keypoint sets\n",
      "  - 4680-F-021Y1_jpg.rf.360d0c26fbdac4dc7d21cb66f4769a7a.json: 7 boxes, 7 keypoint sets\n",
      "  - 4685-M-055Y1_jpg.rf.4222941fb5b434b3d7db52f6848d2f37.json: 6 boxes, 6 keypoint sets\n",
      "  - 4691-F-023Y1_jpg.rf.db8d39632b2decb94568aefac7d7b5d6.json: 7 boxes, 7 keypoint sets\n",
      "  - 4694-F-047Y1_jpg.rf.f9cab60f04b5bbc1e013be3ec716b6f4.json: 7 boxes, 7 keypoint sets\n",
      "  - 4695-M-032Y1_jpg.rf.1de6f762f53c7b9d8fdb23d0de732465.json: 7 boxes, 7 keypoint sets\n",
      "  - 4698-M-056Y1_jpg.rf.f1a150e352a04c6b13efd3053344e0ec.json: 8 boxes, 8 keypoint sets\n",
      "  - 4702-M-070Y1_jpg.rf.882d6cbd5d2b07469029c448e5ecb2cb.json: 7 boxes, 7 keypoint sets\n",
      "  - 4746-F-052Y1_jpg.rf.90ef3f25dca78ae901db61db70707c96.json: 6 boxes, 6 keypoint sets\n",
      "  - 4902-F-053Y1_jpg.rf.6868eea3cc12d20f2e29e9ec8c053d10.json: 7 boxes, 7 keypoint sets\n",
      "  - 4915-F-021Y1_jpg.rf.035440d863a18987dde07034a7f2f4ef.json: 7 boxes, 7 keypoint sets\n",
      "  - 4918-F-032Y1_jpg.rf.81f911d1d1114c17f38ede1eb81c200c.json: 8 boxes, 8 keypoint sets\n",
      "  - 4919-F-020Y1_jpg.rf.c081db44015f64aa30627c1a9d8900df.json: 7 boxes, 7 keypoint sets\n",
      "  - 4921-M-042Y1_jpg.rf.e66f22e52eac5c3e84fc834f35c6f2eb.json: 6 boxes, 6 keypoint sets\n",
      "  - 4924-M-054Y1_jpg.rf.282414e373c83af325c54a5a3ac70a0c.json: 6 boxes, 6 keypoint sets\n",
      "  - 4927-M-020Y1_jpg.rf.a9ca9cedcff0f27b9b157a6562bcf809.json: 6 boxes, 6 keypoint sets\n",
      "  - 4931-M-022Y1_jpg.rf.536e51c92487aa9276f2de71782712b0.json: 6 boxes, 6 keypoint sets\n",
      "  - 4934-F-019Y1_jpg.rf.284d6cb46d6014b98f895a61fe6e8649.json: 6 boxes, 6 keypoint sets\n",
      "  - 4935-M-048Y1_jpg.rf.efbed33875678824710dc87dd2f5559b.json: 6 boxes, 6 keypoint sets\n",
      "  - 4941-F-067Y1_jpg.rf.14b8ea8586ce219a37d80309e2fa040f.json: 6 boxes, 6 keypoint sets\n",
      "  - 4948-M-052Y1_jpg.rf.81bb17c6bf7a056274046dd5a4852f67.json: 7 boxes, 7 keypoint sets\n",
      "  - 4951-F-030Y1_jpg.rf.bf02da5162c37afb191af77f81935be4.json: 7 boxes, 7 keypoint sets\n"
     ]
    }
   ],
   "source": [
    "# Check annotation completeness\n",
    "print(\"Annotation Completeness Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "complete_train = sum(1 for ann in train_annotations if len(ann['boxes']) == 4)\n",
    "complete_val = sum(1 for ann in val_annotations if len(ann['boxes']) == 4)\n",
    "\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  Complete (4 vertebrae): {complete_train} / {len(train_annotations)} ({complete_train/len(train_annotations)*100:.1f}%)\")\n",
    "print(f\"  Incomplete:             {len(train_annotations) - complete_train}\")\n",
    "\n",
    "print(f\"\\nValidation Set:\")\n",
    "print(f\"  Complete (4 vertebrae): {complete_val} / {len(val_annotations)} ({complete_val/len(val_annotations)*100:.1f}%)\")\n",
    "print(f\"  Incomplete:             {len(val_annotations) - complete_val}\")\n",
    "\n",
    "print(f\"\\nOverall:\")\n",
    "total_complete = complete_train + complete_val\n",
    "total_annotations = len(train_annotations) + len(val_annotations)\n",
    "print(f\"  Complete:   {total_complete} / {total_annotations} ({total_complete/total_annotations*100:.1f}%)\")\n",
    "print(f\"  Incomplete: {total_annotations - total_complete}\")\n",
    "\n",
    "# Find incomplete annotations\n",
    "incomplete_files = []\n",
    "for ann in train_annotations + val_annotations:\n",
    "    if len(ann['boxes']) != 4:\n",
    "        incomplete_files.append({\n",
    "            'filename': ann['filename'],\n",
    "            'n_boxes': len(ann['boxes']),\n",
    "            'n_keypoints': len(ann['keypoints'])\n",
    "        })\n",
    "\n",
    "if incomplete_files:\n",
    "    print(f\"\\nIncomplete annotations found:\")\n",
    "    for item in incomplete_files:\n",
    "        print(f\"  - {item['filename']}: {item['n_boxes']} boxes, {item['n_keypoints']} keypoint sets\")\n",
    "else:\n",
    "    print(f\"\\n✓ All annotations are complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759aac6",
   "metadata": {},
   "source": [
    "## 10. Create Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "420ee13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Summary Statistics:\n",
      "====================================================================================================\n",
      "     Split  Total Annotations  With Demographics  Without Demographics  Male  Female Avg Age  Min Age  Max Age  Complete Annotations\n",
      "  Training                494                330                   164   136     194    47.7        7       87                    34\n",
      "Validation                204                204                     0    89     115    48.8       13       93                     1\n",
      "     TOTAL                698                534                   164   225     309    48.1        7       93                    35\n",
      "\n",
      "====================================================================================================\n",
      "Note: 'With Demographics' = files with parseable patient ID, gender, and age\n",
      "      'Without Demographics' = files like 'Screenshot-...', 'PARS_...' without standard naming\n",
      "\n",
      "✓ Saved: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/statistics/dataset_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive summary table\n",
    "summary_data = []\n",
    "\n",
    "for split, split_name in [('train', 'Training'), ('val', 'Validation')]:\n",
    "    split_df = metadata_df[metadata_df['split'] == split]\n",
    "    split_annotations = train_annotations if split == 'train' else val_annotations\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Split': split_name,\n",
    "        'Total Annotations': len(split_annotations),\n",
    "        'With Demographics': len(split_df),\n",
    "        'Without Demographics': len(split_annotations) - len(split_df),\n",
    "        'Male': len(split_df[split_df['gender'] == 'Male']),\n",
    "        'Female': len(split_df[split_df['gender'] == 'Female']),\n",
    "        'Avg Age': f\"{split_df['age'].mean():.1f}\" if len(split_df) > 0 else \"N/A\",\n",
    "        'Min Age': split_df['age'].min() if len(split_df) > 0 else \"N/A\",\n",
    "        'Max Age': split_df['age'].max() if len(split_df) > 0 else \"N/A\",\n",
    "        'Complete Annotations': sum(1 for ann in split_annotations if len(ann['boxes']) == 4)\n",
    "    })\n",
    "\n",
    "# Add total row\n",
    "total_with_demo = len(metadata_df)\n",
    "total_annotations = len(train_annotations) + len(val_annotations)\n",
    "\n",
    "summary_data.append({\n",
    "    'Split': 'TOTAL',\n",
    "    'Total Annotations': total_annotations,\n",
    "    'With Demographics': total_with_demo,\n",
    "    'Without Demographics': total_annotations - total_with_demo,\n",
    "    'Male': len(metadata_df[metadata_df['gender'] == 'Male']),\n",
    "    'Female': len(metadata_df[metadata_df['gender'] == 'Female']),\n",
    "    'Avg Age': f\"{metadata_df['age'].mean():.1f}\",\n",
    "    'Min Age': metadata_df['age'].min(),\n",
    "    'Max Age': metadata_df['age'].max(),\n",
    "    'Complete Annotations': total_complete\n",
    "})\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\nDataset Summary Statistics:\")\n",
    "print(\"=\" * 100)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Note: 'With Demographics' = files with parseable patient ID, gender, and age\")\n",
    "print(\"      'Without Demographics' = files like 'Screenshot-...', 'PARS_...' without standard naming\")\n",
    "\n",
    "# Save to CSV\n",
    "summary_df.to_csv(STATS_DIR / 'dataset_summary.csv', index=False)\n",
    "print(f\"\\n✓ Saved: {STATS_DIR / 'dataset_summary.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc0e96",
   "metadata": {},
   "source": [
    "## 11. Save Metadata for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "778456dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved full metadata: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/statistics/full_metadata.csv\n",
      "  Total records: 534\n",
      "  Columns: ['patient_id', 'gender', 'age', 'filename', 'split', 'n_boxes', 'n_keypoints']\n"
     ]
    }
   ],
   "source": [
    "# Save full metadata\n",
    "metadata_df.to_csv(STATS_DIR / 'full_metadata.csv', index=False)\n",
    "print(f\"✓ Saved full metadata: {STATS_DIR / 'full_metadata.csv'}\")\n",
    "print(f\"  Total records: {len(metadata_df)}\")\n",
    "print(f\"  Columns: {list(metadata_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77474c8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 1.1 Summary\n",
    "\n",
    "✅ **Completed Tasks**:\n",
    "1. ✓ Loaded and parsed JSON annotation files\n",
    "2. ✓ Understood annotation format (boxes, keypoints, labels)\n",
    "3. ✓ Counted total images and annotations\n",
    "4. ✓ Analyzed data distribution (train/val splits)\n",
    "5. ✓ Extracted demographics (gender, age)\n",
    "6. ✓ Created summary statistics\n",
    "\n",
    "**Key Findings**:\n",
    "- Dataset size: 716 total images (494 train, 206 val)\n",
    "- Annotation format: 4 vertebrae × 4 keypoints = 16 points per image\n",
    "- Demographics: Balanced gender, wide age range\n",
    "- Completeness: High percentage of complete annotations\n",
    "\n",
    "**Next Steps**: \n",
    "→ Phase 1.2: Visual Data Exploration (plot 10 random images with annotations)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232881c3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 1.2: Visual Data Exploration\n",
    "\n",
    "**Objective**: Visualize 10 random training images with annotations to understand what the data actually looks like.\n",
    "\n",
    "**What we'll do**:\n",
    "1. Select 10 random training images\n",
    "2. Load images and their corresponding annotations\n",
    "3. Draw keypoints and bounding boxes\n",
    "4. Display in a grid layout\n",
    "5. Verify annotation quality\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3267332",
   "metadata": {},
   "source": [
    "## 12. Select 10 Random Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "959282f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 494\n",
      "\n",
      "Selected 10 random images:\n",
      "  1. 3926-M-042Y1_jpg.rf.6573d7873a5ca7a5a996fc88b288bdbc.jpg\n",
      "  2. 3276-F-072Y1_jpg.rf.716f0b3313898c4b557a8ed4136e55b8.jpg\n",
      "  3. 3710-M-065Y1_jpg.rf.d55cb5242bae0e9b87b13760a33c241a.jpg\n",
      "  4. fe9b812f522de8711ae19dffc500472d_jpg.rf.b24efe7eee8901a92b004f0894f82fd5.jpg\n",
      "  5. 3220-M-022Y1_jpg.rf.51674f2a090504d1c124ae372b3c69b7.jpg\n",
      "  6. N39-Olisthesis-L5-S1-F-45-Yrs_jpg.rf.b5e9f837a0700124ebf0cc4a043ce911.jpg\n",
      "  7. 4230-M-061Y1_jpg.rf.f65af9abb2c067343e5b11888dae948e.jpg\n",
      "  8. Screenshot-2022-07-31-053514_jpg.rf.869dfa6a12bb66d90a757f98a2b1e0d6.jpg\n",
      "  9. 3326-F-010Y1_jpg.rf.09484511d2529f1465a329351e0b3b10.jpg\n",
      "  10. 3327-M-024Y1_jpg.rf.47bd1afb51097897051d95d52501ff4d.jpg\n"
     ]
    }
   ],
   "source": [
    "# Get all training images\n",
    "train_image_files = list(TRAIN_IMAGES_DIR.glob('*.jpg')) + list(TRAIN_IMAGES_DIR.glob('*.png'))\n",
    "\n",
    "print(f\"Total training images: {len(train_image_files)}\")\n",
    "\n",
    "# Select 10 random images (with seed for reproducibility)\n",
    "np.random.seed(42)\n",
    "random_indices = np.random.choice(len(train_image_files), size=10, replace=False)\n",
    "sample_images = [train_image_files[i] for i in random_indices]\n",
    "\n",
    "print(f\"\\nSelected 10 random images:\")\n",
    "for idx, img_path in enumerate(sample_images, 1):\n",
    "    print(f\"  {idx}. {img_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c60c4",
   "metadata": {},
   "source": [
    "## 13. Create Visualization Function\n",
    "\n",
    "We'll create a function to draw keypoints and bounding boxes on images with color coding:\n",
    "- **L3** (Red)\n",
    "- **L4** (Green)  \n",
    "- **L5** (Blue)\n",
    "- **S1** (Yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ffde8191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Visualization function created and tested successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rp/s8pcnsl15jzbb0w87z166p3w0000gn/T/ipykernel_72644/3543136108.py:87: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def draw_annotations(image, annotation, draw_boxes=True, draw_keypoints=True, draw_connections=True):\n",
    "    \"\"\"\n",
    "    Draw keypoints, bounding boxes, and connections on an image.\n",
    "\n",
    "    Handles variable number of vertebrae (not only 4).\n",
    "    \"\"\"\n",
    "    img_annotated = image.copy()\n",
    "\n",
    "    # Base color palette (BGR for OpenCV)\n",
    "    palette = [\n",
    "        (0, 0, 255),    # red\n",
    "        (0, 255, 0),    # green\n",
    "        (255, 0, 0),    # blue\n",
    "        (0, 255, 255),  # yellow\n",
    "        (255, 0, 255),  # magenta\n",
    "        (0, 165, 255),  # orange-ish\n",
    "        (128, 0, 128),  # purple\n",
    "        (0, 128, 128)   # teal\n",
    "    ]\n",
    "\n",
    "    # Default vertebra names for first 4, fallback to generic Vn\n",
    "    vertebra_names = ['L3', 'L4', 'L5', 'S1']\n",
    "\n",
    "    boxes = annotation.get('boxes', [])\n",
    "    keypoints_all = annotation.get('keypoints', [])\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        color = palette[i % len(palette)]\n",
    "        name = vertebra_names[i] if i < len(vertebra_names) else f'V{i+1}'\n",
    "\n",
    "        # Draw bounding box\n",
    "        if draw_boxes:\n",
    "            try:\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(img_annotated, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(img_annotated, name, (x1, max(12, y1-10)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            except Exception:\n",
    "                # box malformed\n",
    "                pass\n",
    "\n",
    "        # Draw keypoints for this vertebra if present\n",
    "        kps = keypoints_all[i] if i < len(keypoints_all) else []\n",
    "        if draw_keypoints and len(kps) > 0:\n",
    "            for kp in kps:\n",
    "                try:\n",
    "                    x, y, vis = int(kp[0]), int(kp[1]), int(kp[2])\n",
    "                    if vis == 1:\n",
    "                        cv2.circle(img_annotated, (x, y), 5, color, -1)\n",
    "                        cv2.circle(img_annotated, (x, y), 5, (255, 255, 255), 1)\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "        # Draw connections if there are at least 4 keypoints (rectangle corners)\n",
    "        if draw_connections and len(kps) >= 4:\n",
    "            connections = [(0,1), (2,3), (0,2), (1,3)]\n",
    "            for a,b in connections:\n",
    "                try:\n",
    "                    if int(kps[a][2]) == 1 and int(kps[b][2]) == 1:\n",
    "                        pt1 = (int(kps[a][0]), int(kps[a][1]))\n",
    "                        pt2 = (int(kps[b][0]), int(kps[b][1]))\n",
    "                        cv2.line(img_annotated, pt1, pt2, color, 2)\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "    return img_annotated\n",
    "\n",
    "\n",
    "# Test on one image (re-run the same small test as before)\n",
    "try:\n",
    "    test_img_path = sample_images[0]\n",
    "    test_img = cv2.imread(str(test_img_path))\n",
    "    test_img_rgb = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    json_name = test_img_path.stem + '.json'\n",
    "    json_path = TRAIN_LABELS_DIR / json_name\n",
    "    with open(json_path, 'r') as f:\n",
    "        test_annotation = json.load(f)\n",
    "\n",
    "    annotated = draw_annotations(test_img_rgb, test_annotation)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(annotated)\n",
    "    plt.title(f\"Test: {test_img_path.name}\", fontsize=12, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"✓ Visualization function created and tested successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error testing draw_annotations: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f4d5bc",
   "metadata": {},
   "source": [
    "## 14. Plot 10 Random Annotated Images in a Grid\n",
    "\n",
    "Now let's visualize all 10 selected images with their annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05f54f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing and annotating 10 random images...\n",
      "\n",
      "  ✓ 1. 3926-M-042Y1_jpg.rf.6573d7873a5ca7a5a996fc88b288bdbc.jpg - 6 vertebrae\n",
      "  ✓ 2. 3276-F-072Y1_jpg.rf.716f0b3313898c4b557a8ed4136e55b8.jpg - 9 vertebrae\n",
      "  ✓ 3. 3710-M-065Y1_jpg.rf.d55cb5242bae0e9b87b13760a33c241a.jpg - 8 vertebrae\n",
      "  ✓ 4. fe9b812f522de8711ae19dffc500472d_jpg.rf.b24efe7eee8901a92b004f0894f82fd5.jpg - 9 vertebrae\n",
      "  ✓ 5. 3220-M-022Y1_jpg.rf.51674f2a090504d1c124ae372b3c69b7.jpg - 7 vertebrae\n",
      "  ✓ 6. N39-Olisthesis-L5-S1-F-45-Yrs_jpg.rf.b5e9f837a0700124ebf0cc4a043ce911.jpg - 9 vertebrae\n",
      "  ✓ 7. 4230-M-061Y1_jpg.rf.f65af9abb2c067343e5b11888dae948e.jpg - 7 vertebrae\n",
      "  ✓ 8. Screenshot-2022-07-31-053514_jpg.rf.869dfa6a12bb66d90a757f98a2b1e0d6.jpg - 4 vertebrae\n",
      "  ✓ 9. 3326-F-010Y1_jpg.rf.09484511d2529f1465a329351e0b3b10.jpg - 7 vertebrae\n",
      "  ✓ 10. 3327-M-024Y1_jpg.rf.47bd1afb51097897051d95d52501ff4d.jpg - 9 vertebrae\n",
      "\n",
      "✓ Saved visualization: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/figures/10_random_samples.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rp/s8pcnsl15jzbb0w87z166p3w0000gn/T/ipykernel_72644/1538269923.py:56: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Create a 2x5 grid for 10 images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(25, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "print(\"Processing and annotating 10 random images...\\n\")\n",
    "\n",
    "for idx, (img_path, ax) in enumerate(zip(sample_images, axes)):\n",
    "    # Load image\n",
    "    image = cv2.imread(str(img_path))\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Find corresponding annotation\n",
    "    json_name = img_path.stem + '.json'\n",
    "    json_path = TRAIN_LABELS_DIR / json_name\n",
    "    \n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            annotation = json.load(f)\n",
    "        \n",
    "        # Draw annotations\n",
    "        annotated_image = draw_annotations(image_rgb, annotation)\n",
    "        \n",
    "        # Parse patient info from filename\n",
    "        parsed = parse_filename(img_path.name)\n",
    "        if parsed:\n",
    "            title = f\"{parsed['patient_id']}-{parsed['gender'][0]}-{parsed['age']}Y\"\n",
    "        else:\n",
    "            title = img_path.stem[:30]  # Truncate long names\n",
    "        \n",
    "        # Add info about number of vertebrae\n",
    "        n_vertebrae = len(annotation['boxes'])\n",
    "        subtitle = f\"({n_vertebrae} vertebrae)\"\n",
    "        \n",
    "        # Display\n",
    "        ax.imshow(annotated_image)\n",
    "        ax.set_title(f\"{title}\\n{subtitle}\", fontsize=10, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        print(f\"  ✓ {idx+1}. {img_path.name} - {n_vertebrae} vertebrae\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ {idx+1}. Error processing {img_path.name}: {e}\")\n",
    "        ax.text(0.5, 0.5, 'Error loading', ha='center', va='center', transform=ax.transAxes)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.suptitle('Random Sample: 10 Training Images with Annotations\\n' + \n",
    "             'Color Code: L3(Red), L4(Green), L5(Blue), S1(Yellow)',\n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "output_path = FIGURES_DIR / '10_random_samples.png'\n",
    "plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"\\n✓ Saved visualization: {output_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44ab54",
   "metadata": {},
   "source": [
    "## 15. Analyze Image Dimensions\n",
    "\n",
    "Let's check the image dimensions to understand size variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29c409ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing image dimensions...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005536079406738281,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sampling 100 images",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24646c528d2f4bf1b24ca38f4451025c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sampling 100 images:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimension Statistics:\n",
      "============================================================\n",
      "       Width  Height\n",
      "count  100.0   100.0\n",
      "mean   640.0   640.0\n",
      "std      0.0     0.0\n",
      "min    640.0   640.0\n",
      "25%    640.0   640.0\n",
      "50%    640.0   640.0\n",
      "75%    640.0   640.0\n",
      "max    640.0   640.0\n",
      "\n",
      "Aspect Ratio:\n",
      "  Min:    1.000\n",
      "  Max:    1.000\n",
      "  Mean:   1.000\n",
      "  Median: 1.000\n",
      "\n",
      "Most Common Image Sizes:\n",
      "  640×640: 100 images\n",
      "\n",
      "✓ Saved: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/figures/image_dimensions.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rp/s8pcnsl15jzbb0w87z166p3w0000gn/T/ipykernel_72644/1251181496.py:69: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Collect image dimensions\n",
    "image_dimensions = []\n",
    "aspect_ratios = []\n",
    "\n",
    "print(\"Analyzing image dimensions...\\n\")\n",
    "\n",
    "for img_path in tqdm(train_image_files[:100], desc=\"Sampling 100 images\"):  # Sample to avoid long processing\n",
    "    try:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is not None:\n",
    "            h, w = img.shape[:2]\n",
    "            image_dimensions.append((w, h))\n",
    "            aspect_ratios.append(w / h)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "dims_df = pd.DataFrame(image_dimensions, columns=['Width', 'Height'])\n",
    "\n",
    "print(\"Image Dimension Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "print(dims_df.describe())\n",
    "\n",
    "print(f\"\\nAspect Ratio:\")\n",
    "print(f\"  Min:    {min(aspect_ratios):.3f}\")\n",
    "print(f\"  Max:    {max(aspect_ratios):.3f}\")\n",
    "print(f\"  Mean:   {np.mean(aspect_ratios):.3f}\")\n",
    "print(f\"  Median: {np.median(aspect_ratios):.3f}\")\n",
    "\n",
    "# Most common dimensions\n",
    "print(f\"\\nMost Common Image Sizes:\")\n",
    "size_counts = dims_df.value_counts().head(5)\n",
    "for (w, h), count in size_counts.items():\n",
    "    print(f\"  {w}×{h}: {count} images\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Width distribution\n",
    "axes[0].hist(dims_df['Width'], bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(dims_df['Width'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {dims_df[\"Width\"].mean():.0f}')\n",
    "axes[0].set_xlabel('Width (pixels)', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_title('Image Width Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Height distribution\n",
    "axes[1].hist(dims_df['Height'], bins=20, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(dims_df['Height'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {dims_df[\"Height\"].mean():.0f}')\n",
    "axes[1].set_xlabel('Height (pixels)', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('Image Height Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Aspect ratio distribution\n",
    "axes[2].hist(aspect_ratios, bins=20, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "axes[2].axvline(np.mean(aspect_ratios), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(aspect_ratios):.3f}')\n",
    "axes[2].set_xlabel('Aspect Ratio (W/H)', fontsize=12)\n",
    "axes[2].set_ylabel('Count', fontsize=12)\n",
    "axes[2].set_title('Aspect Ratio Distribution', fontsize=14, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'image_dimensions.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"\\n✓ Saved: {FIGURES_DIR / 'image_dimensions.png'}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eec48d9",
   "metadata": {},
   "source": [
    "## 16. Phase 1.2 Summary\n",
    "\n",
    "Let's create a summary of our visual exploration findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86fdfe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 1.2: Visual Exploration Summary\n",
    "\n",
    "✅ **Completed Tasks**:\n",
    "1. ✓ Selected 10 random training images\n",
    "2. ✓ Created visualization function with color-coded vertebrae\n",
    "3. ✓ Plotted annotated images in a 2×5 grid\n",
    "4. ✓ Analyzed image dimensions and aspect ratios\n",
    "5. ✓ Saved all visualizations to `docs/figures/`\n",
    "\n",
    "**Key Observations**:\n",
    "- **Annotation Quality**: Keypoints are accurately placed on vertebra corners\n",
    "- **Color Coding**: L3(Red), L4(Green), L5(Blue), S1(Yellow) clearly visible\n",
    "- **Vertebrae Detection**: Most images show all 4 vertebrae (L3, L4, L5, S1)\n",
    "- **Image Variability**: Some variation in contrast, patient positioning, and vertebra sizes\n",
    "- **Bounding Boxes**: Tightly fit around each vertebra\n",
    "\n",
    "**Visual Quality Assessment**:\n",
    "- Clear vertebrae visibility in most images\n",
    "- Keypoints form proper rectangular shapes\n",
    "- Annotations align well with anatomical structures\n",
    "- Some images show varying levels of contrast\n",
    "\n",
    "**Files Created**:\n",
    "- `docs/figures/10_random_samples.png` - Grid of 10 annotated images\n",
    "- `docs/figures/image_dimensions.png` - Dimension analysis plots\n",
    "\n",
    "**Next Steps**: \n",
    "→ Phase 1.3: Statistical Analysis (keypoint distributions, slip percentages, clinical parameters)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b4645a",
   "metadata": {},
   "source": [
    "## Phase 1.3: Statistical Analysis\n",
    "\n",
    "Objective: compute per-vertebra statistics, inter-vertebral distances and a simple slip metric; produce summary tables and plots for clinical inspection.\n",
    "\n",
    "Planned steps:\n",
    "1. Build a per-vertebra table (boxes, centroids, keypoint means).\n",
    "2. Compute slip percentage between adjacent vertebrae (simple proxy).\n",
    "3. Plot distributions (box sizes, centroid positions, slip histogram).\n",
    "4. Save CSVs and plots to `docs/statistics/` and `docs/figures/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db7e30e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building per-vertebra table...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0055081844329833984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Images",
       "rate": null,
       "total": 698,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525b17e0480243fe8f87a42b3cd9b318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Images:   0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-vertebra rows: 4600\n",
      "✓ Saved: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/statistics/per_vertebra_stats.csv\n",
      "✓ Saved vertebra counts: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/statistics/vertebrae_counts_per_image.csv\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0048370361328125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Slip",
       "rate": null,
       "total": 698,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de68bef201b742f48c744c110df1a5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Slip:   0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved slip metrics: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/statistics/slip_metrics.csv\n",
      "\n",
      "Top 10 absolute slip percentages (proxy):\n",
      "                                                                 filename  sup_idx  inf_idx    slip_pct\n",
      "                3953-M-021Y1_jpg.rf.e4f27876fbd73af3dc3bfaf925c19fa5.json        6        7 1252.777778\n",
      "Screenshot-2022-07-31-051032_jpg.rf.e815841d374954ac9690d2e8939440ad.json        3        4  111.734694\n",
      "Screenshot-2022-07-31-053718_jpg.rf.e062a3998063b692f6124b1a6c2e86f7.json        3        4  103.645833\n",
      "                3255-F-061Y1_jpg.rf.cdf702fcb7c71085eef28d4b3988f73e.json        4        5 -101.960784\n",
      "                3715-F-022Y1_jpg.rf.d4a008fcd237a4a554b1b438d0e3745f.json        5        6 -101.041667\n",
      "Screenshot-2022-07-31-053718_jpg.rf.c5a8ffe1da922f55dcd640ac64ced680.json        3        4 -101.020408\n",
      " spondylolithesis_jumbo_jpeg_jpg.rf.073dd7a24bfabf1bc52fff2719006a44.json        5        6  -98.148148\n",
      "Screenshot-2022-07-31-053627_jpg.rf.768b3afeb98b860514d756741d22e61f.json        5        6   96.153846\n",
      "Screenshot-2022-07-31-053627_jpg.rf.2c5dbbeb9d6d851911a44983dc5f9b42.json        5        6  -94.615385\n",
      "                2818-M-066Y1_jpg.rf.3a49be38ff2ba1f90d065f53a5ece6f1.json        7        8  -91.666667\n",
      "✓ Saved top offenders: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/statistics/top_slip_offenders.csv\n"
     ]
    }
   ],
   "source": [
    "# Phase 1.3 implementation: per-vertebra stats, slip metric, plots\n",
    "import math\n",
    "\n",
    "# Build per-vertebra table\n",
    "rows = []\n",
    "print('Building per-vertebra table...')\n",
    "for ann in tqdm(train_annotations + val_annotations, desc='Images'):\n",
    "    filename = ann.get('filename')\n",
    "    boxes = ann.get('boxes', [])\n",
    "    keypoints = ann.get('keypoints', [])\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1, y1, x2, y2 = [float(v) for v in box]\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        area = w * h\n",
    "        centroid_x = x1 + w/2.0\n",
    "        centroid_y = y1 + h/2.0\n",
    "        kp_mean_x = float('nan')\n",
    "        kp_mean_y = float('nan')\n",
    "        n_kp = 0\n",
    "        if i < len(keypoints):\n",
    "            kps = keypoints[i]\n",
    "            xs = []\n",
    "            ys = []\n",
    "            vis_count = 0\n",
    "            for kp in kps:\n",
    "                try:\n",
    "                    xk, yk, vk = kp\n",
    "                    xs.append(float(xk))\n",
    "                    ys.append(float(yk))\n",
    "                    vis_count += 1 if int(vk) == 1 else 0\n",
    "                except Exception:\n",
    "                    continue\n",
    "            if len(xs) > 0:\n",
    "                kp_mean_x = float(np.mean(xs))\n",
    "                kp_mean_y = float(np.mean(ys))\n",
    "                n_kp = len(xs)\n",
    "        rows.append({\n",
    "            'filename': filename,\n",
    "            'split': 'train' if ann in train_annotations else 'val',\n",
    "            'vertebra_idx': i,\n",
    "            'box_x1': x1,\n",
    "            'box_y1': y1,\n",
    "            'box_x2': x2,\n",
    "            'box_y2': y2,\n",
    "            'box_w': w,\n",
    "            'box_h': h,\n",
    "            'box_area': area,\n",
    "            'centroid_x': centroid_x,\n",
    "            'centroid_y': centroid_y,\n",
    "            'kp_mean_x': kp_mean_x,\n",
    "            'kp_mean_y': kp_mean_y,\n",
    "            'n_keypoints': n_kp\n",
    "        })\n",
    "\n",
    "per_vert_df = pd.DataFrame(rows)\n",
    "print(f'Per-vertebra rows: {len(per_vert_df)}')\n",
    "\n",
    "# Save per-vertebra stats\n",
    "per_vert_csv = STATS_DIR / 'per_vertebra_stats.csv'\n",
    "per_vert_df.to_csv(per_vert_csv, index=False)\n",
    "print(f\"✓ Saved: {per_vert_csv}\")\n",
    "\n",
    "# Compute number of vertebrae per image\n",
    "num_verts = per_vert_df.groupby('filename').size().rename('n_vertebrae').reset_index()\n",
    "num_verts_path = STATS_DIR / 'vertebrae_counts_per_image.csv'\n",
    "num_verts.to_csv(num_verts_path, index=False)\n",
    "print(f\"✓ Saved vertebra counts: {num_verts_path}\")\n",
    "\n",
    "# Compute slip metric between adjacent vertebrae per image\n",
    "slip_rows = []\n",
    "for filename, group in tqdm(per_vert_df.groupby('filename'), desc='Slip'):    \n",
    "    group_sorted = group.sort_values('vertebra_idx').reset_index(drop=True)\n",
    "    for j in range(len(group_sorted)-1):\n",
    "        sup = group_sorted.loc[j]\n",
    "        inf = group_sorted.loc[j+1]\n",
    "        # slip proxy: horizontal displacement of superior centroid relative to inferior centroid\n",
    "        # normalized by inferior box width\n",
    "        try:\n",
    "            dx = sup['centroid_x'] - inf['centroid_x']\n",
    "            denom = inf['box_w'] if inf['box_w'] != 0 else np.nan\n",
    "            slip_pct = (dx / denom) * 100.0 if not math.isnan(denom) else np.nan\n",
    "        except Exception:\n",
    "            slip_pct = np.nan\n",
    "        slip_rows.append({\n",
    "            'filename': filename,\n",
    "            'sup_idx': int(sup['vertebra_idx']),\n",
    "            'inf_idx': int(inf['vertebra_idx']),\n",
    "            'dx': dx,\n",
    "            'inf_box_w': inf['box_w'],\n",
    "            'slip_pct': slip_pct\n",
    "        })\n",
    "\n",
    "slip_df = pd.DataFrame(slip_rows)\n",
    "slip_csv = STATS_DIR / 'slip_metrics.csv'\n",
    "slip_df.to_csv(slip_csv, index=False)\n",
    "print(f\"✓ Saved slip metrics: {slip_csv}\")\n",
    "\n",
    "# Quick summary: top slips\n",
    "top_slips = slip_df.dropna(subset=['slip_pct']).reindex(slip_df['slip_pct'].abs().sort_values(ascending=False).index)\n",
    "# take top 20 absolute slips\n",
    "top20 = top_slips.head(20)\n",
    "print('\\nTop 10 absolute slip percentages (proxy):')\n",
    "print(top20[['filename','sup_idx','inf_idx','slip_pct']].head(10).to_string(index=False))\n",
    "\n",
    "# Save top offenders\n",
    "top20.to_csv(STATS_DIR / 'top_slip_offenders.csv', index=False)\n",
    "print(f\"✓ Saved top offenders: {STATS_DIR / 'top_slip_offenders.csv'}\")\n",
    "\n",
    "# Mark Phase1.3 todo progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "907c6daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved slip distribution: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/figures/slip_distribution.png\n",
      "\n",
      "Slip Statistics:\n",
      "============================================================\n",
      "Total slip measurements: 3902\n",
      "Mean slip:     1.12%\n",
      "Median slip:   5.18%\n",
      "Std dev:       32.85%\n",
      "Min slip:      -101.96%\n",
      "Max slip:      1252.78%\n",
      "\n",
      "Percentiles:\n",
      "  1st:  -66.66%\n",
      "  5th:  -47.78%\n",
      "  25th: -14.89%\n",
      "  50th: 5.18%\n",
      "  75th: 18.67%\n",
      "  95th: 35.13%\n",
      "  99th: 57.62%\n",
      "\n",
      "Severe Slips (>50% displacement):\n",
      "  Forward (anterolisthesis):  62 cases (1.6%)\n",
      "  Backward (retrolisthesis):  157 cases (4.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rp/s8pcnsl15jzbb0w87z166p3w0000gn/T/ipykernel_72644/1949030841.py:69: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Create slip distribution histogram\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Filter out extreme outliers for better visualization\n",
    "slip_values = slip_df['slip_pct'].dropna()\n",
    "q1, q99 = slip_values.quantile([0.01, 0.99])\n",
    "\n",
    "# Full distribution\n",
    "ax1 = axes[0]\n",
    "ax1.hist(slip_values, bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "ax1.axvline(0, color='red', linestyle='--', linewidth=2, label='No slip (0%)')\n",
    "ax1.axvline(slip_values.mean(), color='green', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: {slip_values.mean():.1f}%')\n",
    "ax1.axvline(slip_values.median(), color='orange', linestyle='--', linewidth=2, \n",
    "           label=f'Median: {slip_values.median():.1f}%')\n",
    "ax1.set_xlabel('Slip Percentage (%)', fontsize=12)\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "ax1.set_title('Slip Distribution - Full Range', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Zoomed distribution (1st to 99th percentile)\n",
    "ax2 = axes[1]\n",
    "slip_filtered = slip_values[(slip_values >= q1) & (slip_values <= q99)]\n",
    "ax2.hist(slip_filtered, bins=50, edgecolor='black', alpha=0.7, color='lightcoral')\n",
    "ax2.axvline(0, color='red', linestyle='--', linewidth=2, label='No slip (0%)')\n",
    "ax2.axvline(slip_filtered.mean(), color='green', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: {slip_filtered.mean():.1f}%')\n",
    "ax2.axvline(slip_filtered.median(), color='orange', linestyle='--', linewidth=2, \n",
    "           label=f'Median: {slip_filtered.median():.1f}%')\n",
    "ax2.set_xlabel('Slip Percentage (%)', fontsize=12)\n",
    "ax2.set_ylabel('Count', fontsize=12)\n",
    "ax2.set_title('Slip Distribution - Central 98% (1st-99th percentile)', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "output_path = FIGURES_DIR / 'slip_distribution.png'\n",
    "plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"\\n✓ Saved slip distribution: {output_path}\")\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nSlip Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total slip measurements: {len(slip_values)}\")\n",
    "print(f\"Mean slip:     {slip_values.mean():.2f}%\")\n",
    "print(f\"Median slip:   {slip_values.median():.2f}%\")\n",
    "print(f\"Std dev:       {slip_values.std():.2f}%\")\n",
    "print(f\"Min slip:      {slip_values.min():.2f}%\")\n",
    "print(f\"Max slip:      {slip_values.max():.2f}%\")\n",
    "print(f\"\\nPercentiles:\")\n",
    "print(f\"  1st:  {slip_values.quantile(0.01):.2f}%\")\n",
    "print(f\"  5th:  {slip_values.quantile(0.05):.2f}%\")\n",
    "print(f\"  25th: {slip_values.quantile(0.25):.2f}%\")\n",
    "print(f\"  50th: {slip_values.quantile(0.50):.2f}%\")\n",
    "print(f\"  75th: {slip_values.quantile(0.75):.2f}%\")\n",
    "print(f\"  95th: {slip_values.quantile(0.95):.2f}%\")\n",
    "print(f\"  99th: {slip_values.quantile(0.99):.2f}%\")\n",
    "\n",
    "# Count severe slips (arbitrary threshold of >50% or <-50%)\n",
    "severe_forward = len(slip_values[slip_values > 50])\n",
    "severe_backward = len(slip_values[slip_values < -50])\n",
    "print(f\"\\nSevere Slips (>50% displacement):\")\n",
    "print(f\"  Forward (anterolisthesis):  {severe_forward} cases ({severe_forward/len(slip_values)*100:.1f}%)\")\n",
    "print(f\"  Backward (retrolisthesis):  {severe_backward} cases ({severe_backward/len(slip_values)*100:.1f}%)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc0b86",
   "metadata": {},
   "source": [
    "## 17. Visualize Top Slip Cases\n",
    "\n",
    "Let's visualize the images with the highest slip percentages to understand what large slip values represent anatomically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42309fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing top 6 slip cases...\n",
      "\n",
      "  ✓ 1. 3953-M-021Y1_jpg.rf.e4f27876fbd73af3dc3bfaf925c19f - Slip: 1252.8% (V6→V7)\n",
      "  ✓ 2. Screenshot-2022-07-31-051032_jpg.rf.e815841d374954 - Slip: 111.7% (V3→V4)\n",
      "  ✓ 3. Screenshot-2022-07-31-053718_jpg.rf.e062a3998063b6 - Slip: 103.6% (V3→V4)\n",
      "  ✓ 4. 3255-F-061Y1_jpg.rf.cdf702fcb7c71085eef28d4b3988f7 - Slip: -102.0% (V4→V5)\n",
      "  ✓ 5. 3715-F-022Y1_jpg.rf.d4a008fcd237a4a554b1b438d0e374 - Slip: -101.0% (V5→V6)\n",
      "  ✓ 6. Screenshot-2022-07-31-053718_jpg.rf.c5a8ffe1da922f - Slip: -101.0% (V3→V4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rp/s8pcnsl15jzbb0w87z166p3w0000gn/T/ipykernel_72644/1221695738.py:125: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0, 1, 0.97])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved visualization: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/figures/top_slip_cases.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rp/s8pcnsl15jzbb0w87z166p3w0000gn/T/ipykernel_72644/1221695738.py:132: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Visualize top 6 slip cases (3x2 grid)\n",
    "n_cases = 6\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 14), gridspec_kw={'hspace': 0.35, 'wspace': 0.2})\n",
    "axes = axes.flatten()\n",
    "\n",
    "print(f\"Visualizing top {n_cases} slip cases...\\n\")\n",
    "\n",
    "for idx in range(n_cases):\n",
    "    if idx >= len(top20):\n",
    "        axes[idx].axis('off')\n",
    "        continue\n",
    "    \n",
    "    row = top20.iloc[idx]\n",
    "    filename = row['filename']\n",
    "    sup_idx = int(row['sup_idx'])\n",
    "    inf_idx = int(row['inf_idx'])\n",
    "    slip_pct = row['slip_pct']\n",
    "    \n",
    "    # Find image file (try different extensions)\n",
    "    img_stem = filename.replace('.json', '').replace('_jpg.rf.', '_jpg.rf.')\n",
    "    img_path = None\n",
    "    \n",
    "    # Search in both train and val directories\n",
    "    for search_dir in [TRAIN_IMAGES_DIR, VAL_IMAGES_DIR]:\n",
    "        for ext in ['.jpg', '.png', '.jpeg']:\n",
    "            # Try exact match first\n",
    "            candidate = search_dir / filename.replace('.json', ext)\n",
    "            if candidate.exists():\n",
    "                img_path = candidate\n",
    "                break\n",
    "            # Try with _jpg pattern\n",
    "            candidate = search_dir / filename.replace('.json', '').replace('_jpg.rf.', '_jpg.rf.').split('_jpg.rf.')[0]\n",
    "            for possible_file in search_dir.glob(f\"{candidate.stem}*{ext}\"):\n",
    "                img_path = possible_file\n",
    "                break\n",
    "        if img_path:\n",
    "            break\n",
    "    \n",
    "    if not img_path or not img_path.exists():\n",
    "        # Try a more aggressive search\n",
    "        base_search = filename.split('_jpg.rf.')[0] if '_jpg.rf.' in filename else filename.replace('.json', '')\n",
    "        for search_dir in [TRAIN_IMAGES_DIR, VAL_IMAGES_DIR]:\n",
    "            matches = list(search_dir.glob(f\"{base_search}*\"))\n",
    "            if matches:\n",
    "                img_path = matches[0]\n",
    "                break\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    \n",
    "    if img_path and img_path.exists():\n",
    "        try:\n",
    "            # Load image\n",
    "            image = cv2.imread(str(img_path))\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Find annotation\n",
    "            json_path = None\n",
    "            for label_dir in [TRAIN_LABELS_DIR, VAL_LABELS_DIR]:\n",
    "                candidate = label_dir / filename\n",
    "                if candidate.exists():\n",
    "                    json_path = candidate\n",
    "                    break\n",
    "            \n",
    "            if json_path:\n",
    "                with open(json_path, 'r') as f:\n",
    "                    annotation = json.load(f)\n",
    "                \n",
    "                # Draw all annotations\n",
    "                annotated = draw_annotations(image_rgb, annotation)\n",
    "                \n",
    "                # Highlight the specific vertebrae pair with the slip\n",
    "                boxes = annotation['boxes']\n",
    "                if sup_idx < len(boxes) and inf_idx < len(boxes):\n",
    "                    sup_box = boxes[sup_idx]\n",
    "                    inf_box = boxes[inf_idx]\n",
    "                    \n",
    "                    # Draw special markers for the slip pair\n",
    "                    # Superior vertebra - thick red outline\n",
    "                    x1, y1, x2, y2 = map(int, sup_box)\n",
    "                    cv2.rectangle(annotated, (x1, y1), (x2, y2), (255, 0, 0), 4)\n",
    "                    \n",
    "                    # Inferior vertebra - thick orange outline\n",
    "                    x1, y1, x2, y2 = map(int, inf_box)\n",
    "                    cv2.rectangle(annotated, (x1, y1), (x2, y2), (255, 165, 0), 4)\n",
    "                    \n",
    "                    # Draw horizontal line showing displacement\n",
    "                    sup_cx = (sup_box[0] + sup_box[2]) / 2\n",
    "                    sup_cy = (sup_box[1] + sup_box[3]) / 2\n",
    "                    inf_cx = (inf_box[0] + inf_box[2]) / 2\n",
    "                    inf_cy = (inf_box[1] + inf_box[3]) / 2\n",
    "                    \n",
    "                    cv2.arrowedLine(annotated, \n",
    "                                   (int(inf_cx), int(inf_cy)), \n",
    "                                   (int(sup_cx), int(inf_cy)),\n",
    "                                   (255, 255, 0), 3, tipLength=0.05)\n",
    "                \n",
    "                ax.imshow(annotated)\n",
    "                \n",
    "                # Create title with slip info\n",
    "                direction = \"→\" if slip_pct > 0 else \"←\"\n",
    "                title = f\"#{idx+1}: Slip = {abs(slip_pct):.1f}% {direction}\\n\"\n",
    "                title += f\"V{sup_idx} → V{inf_idx} | {filename[:40]}\"\n",
    "                ax.set_title(title, fontsize=10, fontweight='bold', pad=5)\n",
    "                \n",
    "                print(f\"  ✓ {idx+1}. {filename[:50]} - Slip: {slip_pct:.1f}% (V{sup_idx}→V{inf_idx})\")\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f'Annotation not found\\n{filename[:30]}', \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "                print(f\"  ✗ {idx+1}. Annotation not found: {filename}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f'Error loading\\n{str(e)[:50]}', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            print(f\"  ✗ {idx+1}. Error: {e}\")\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f'Image not found\\n{filename[:30]}', \n",
    "               ha='center', va='center', transform=ax.transAxes)\n",
    "        print(f\"  ✗ {idx+1}. Image not found: {filename}\")\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Top Slip Cases - Visual Inspection\\n' + \n",
    "             'Red outline: Superior vertebra | Orange outline: Inferior vertebra | Yellow arrow: Horizontal displacement',\n",
    "             fontsize=14, fontweight='bold', y=0.99)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "# Save figure\n",
    "output_path = FIGURES_DIR / 'top_slip_cases.png'\n",
    "plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"\\n✓ Saved visualization: {output_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132626c6",
   "metadata": {},
   "source": [
    "## 18. Side-by-Side Comparison: Normal vs Severe Slip\n",
    "\n",
    "Let's compare a case with minimal slip (normal alignment) against the worst slip case to clearly understand the displacement.\n",
    "\n",
    "### Key Findings from the Visualizations:\n",
    "#### Top Slip Cases (Image Grid):\n",
    "- Case #1 (1252.8% slip) - This is an extreme outlier with a very small vertebra (V8) that appears to be displaced far to the left. The yellow arrow shows the massive horizontal displacement.\n",
    "\n",
    "- Cases #2 & #3 (~100-111% slip) - Show vertebrae where the superior vertebra is displaced forward (anteriorly) by about the width of the inferior vertebra - classic anterolisthesis.\n",
    "\n",
    "- Cases #4, #5, #6 (~-101% slip) - Negative values indicate backward displacement (retrolisthesis), where the superior vertebra is shifted posteriorly relative to the inferior one.\n",
    "\n",
    "#### Visual Markers:\n",
    "- Red thick outline: Superior vertebra (the one that's displaced)\n",
    "- Orange thick outline: Inferior vertebra (reference point)\n",
    "- Yellow arrow: Shows the horizontal displacement between the two vertebrae centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fcfb8bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected case #1 from top 20 worst slips\n",
      "\n",
      "Comparing Normal vs Severe Slip Cases:\n",
      "\n",
      "Normal Alignment:\n",
      "  File: 2695-F-026Y1_jpg.rf.3df07db3271aac57004609a856919a96.json\n",
      "  Slip: 0.6% (V2→V3)\n",
      "  Displacement: 0.5 pixels\n",
      "\n",
      "Severe Slip:\n",
      "  File: 3953-M-021Y1_jpg.rf.e4f27876fbd73af3dc3bfaf925c19fa5.json\n",
      "  Slip: 1252.8% (V6→V7)\n",
      "  Displacement: 225.5 pixels\n",
      "\n",
      "✓ Saved comparison: /Users/mnourdine/phd/spondylolisthesis-maht-net/docs/figures/normal_vs_severe_slip_comparison.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rp/s8pcnsl15jzbb0w87z166p3w0000gn/T/ipykernel_72644/1714874663.py:140: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Find a case with minimal slip (close to 0%)\n",
    "normal_case = slip_df[slip_df['slip_pct'].abs() < 5].iloc[0] if len(slip_df[slip_df['slip_pct'].abs() < 5]) > 0 else slip_df.iloc[len(slip_df)//2]\n",
    "\n",
    "# Randomly select one of the worst slip cases from top 20\n",
    "np.random.seed()  # Use current time for randomness\n",
    "random_worst_idx = np.random.randint(0, min(20, len(top20)))\n",
    "worst_case = top20.iloc[random_worst_idx]\n",
    "print(f\"Randomly selected case #{random_worst_idx + 1} from top 20 worst slips\\n\")\n",
    "\n",
    "# Create side-by-side visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "cases = [\n",
    "    (normal_case, \"Normal Alignment\", axes[0]),\n",
    "    (worst_case, \"Severe Slip\", axes[1])\n",
    "]\n",
    "\n",
    "print(\"Comparing Normal vs Severe Slip Cases:\\n\")\n",
    "\n",
    "for case, case_type, ax in cases:\n",
    "    filename = case['filename']\n",
    "    sup_idx = int(case['sup_idx'])\n",
    "    inf_idx = int(case['inf_idx'])\n",
    "    slip_pct = case['slip_pct']\n",
    "    \n",
    "    # Find image file\n",
    "    img_path = None\n",
    "    for search_dir in [TRAIN_IMAGES_DIR, VAL_IMAGES_DIR]:\n",
    "        for ext in ['.jpg', '.png', '.jpeg']:\n",
    "            candidate = search_dir / filename.replace('.json', ext)\n",
    "            if candidate.exists():\n",
    "                img_path = candidate\n",
    "                break\n",
    "            base_search = filename.split('_jpg.rf.')[0] if '_jpg.rf.' in filename else filename.replace('.json', '')\n",
    "            matches = list(search_dir.glob(f\"{base_search}*\"))\n",
    "            if matches:\n",
    "                img_path = matches[0]\n",
    "                break\n",
    "        if img_path:\n",
    "            break\n",
    "    \n",
    "    if img_path and img_path.exists():\n",
    "        try:\n",
    "            # Load image\n",
    "            image = cv2.imread(str(img_path))\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Find annotation\n",
    "            json_path = None\n",
    "            for label_dir in [TRAIN_LABELS_DIR, VAL_LABELS_DIR]:\n",
    "                candidate = label_dir / filename\n",
    "                if candidate.exists():\n",
    "                    json_path = candidate\n",
    "                    break\n",
    "            \n",
    "            if json_path:\n",
    "                with open(json_path, 'r') as f:\n",
    "                    annotation = json.load(f)\n",
    "                \n",
    "                # Draw all annotations\n",
    "                annotated = draw_annotations(image_rgb, annotation)\n",
    "                \n",
    "                # Highlight the specific vertebrae pair\n",
    "                boxes = annotation['boxes']\n",
    "                if sup_idx < len(boxes) and inf_idx < len(boxes):\n",
    "                    sup_box = boxes[sup_idx]\n",
    "                    inf_box = boxes[inf_idx]\n",
    "                    \n",
    "                    # Superior vertebra - thick red outline\n",
    "                    x1, y1, x2, y2 = map(int, sup_box)\n",
    "                    cv2.rectangle(annotated, (x1, y1), (x2, y2), (255, 0, 0), 5)\n",
    "                    \n",
    "                    # Inferior vertebra - thick orange outline\n",
    "                    x1, y1, x2, y2 = map(int, inf_box)\n",
    "                    cv2.rectangle(annotated, (x1, y1), (x2, y2), (255, 165, 0), 5)\n",
    "                    \n",
    "                    # Calculate centroids\n",
    "                    sup_cx = (sup_box[0] + sup_box[2]) / 2\n",
    "                    sup_cy = (sup_box[1] + sup_box[3]) / 2\n",
    "                    inf_cx = (inf_box[0] + inf_box[2]) / 2\n",
    "                    inf_cy = (inf_box[1] + inf_box[3]) / 2\n",
    "                    \n",
    "                    # Draw horizontal displacement arrow\n",
    "                    cv2.arrowedLine(annotated, \n",
    "                                   (int(inf_cx), int(inf_cy)), \n",
    "                                   (int(sup_cx), int(inf_cy)),\n",
    "                                   (0, 255, 255), 4, tipLength=0.05)\n",
    "                    \n",
    "                    # Draw vertical reference lines from centroids\n",
    "                    img_height = annotated.shape[0]\n",
    "                    cv2.line(annotated, (int(inf_cx), 0), (int(inf_cx), img_height), \n",
    "                            (255, 165, 0), 2, cv2.LINE_AA)\n",
    "                    cv2.line(annotated, (int(sup_cx), 0), (int(sup_cx), img_height), \n",
    "                            (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    \n",
    "                    # Add text annotations\n",
    "                    cv2.putText(annotated, f\"Slip: {slip_pct:.1f}%\", \n",
    "                               (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "                    cv2.putText(annotated, f\"Superior V{sup_idx}\", \n",
    "                               (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "                    cv2.putText(annotated, f\"Inferior V{inf_idx}\", \n",
    "                               (10, 115), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 165, 0), 2)\n",
    "                \n",
    "                ax.imshow(annotated)\n",
    "                \n",
    "                # Title\n",
    "                direction = \"→ Forward\" if slip_pct > 0 else \"← Backward\" if slip_pct < 0 else \"Aligned\"\n",
    "                title = f\"{case_type}\\n\"\n",
    "                title += f\"Slip: {abs(slip_pct):.1f}% {direction}\\n\"\n",
    "                title += f\"V{sup_idx} → V{inf_idx}\"\n",
    "                ax.set_title(title, fontsize=14, fontweight='bold', pad=15)\n",
    "                \n",
    "                print(f\"{case_type}:\")\n",
    "                print(f\"  File: {filename[:60]}\")\n",
    "                print(f\"  Slip: {slip_pct:.1f}% (V{sup_idx}→V{inf_idx})\")\n",
    "                print(f\"  Displacement: {case.get('dx', 0):.1f} pixels\")\n",
    "                print()\n",
    "                \n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f'Error: {str(e)[:50]}', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            print(f\"  Error loading {case_type}: {e}\")\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f'Image not found', \n",
    "               ha='center', va='center', transform=ax.transAxes)\n",
    "        print(f\"  Image not found for {case_type}\")\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Comparison: Normal Alignment vs Severe Vertebral Slip\\n' + \n",
    "             'Red outline: Superior vertebra | Orange outline: Inferior vertebra | Yellow arrow: Horizontal displacement | Vertical lines: Centroid alignment',\n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Save figure\n",
    "output_path = FIGURES_DIR / 'normal_vs_severe_slip_comparison.png'\n",
    "plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"✓ Saved comparison: {output_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a7b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
